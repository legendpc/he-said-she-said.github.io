--- Log opened Sun Dec 02 00:00:48 2012
00:02 < harrydog> a few of the examples write about setting the cookie with http first, then authorizing through the websocket. something about the flash fallback unable to set cookie headers, should i just write the set cookie code in the client's js?
00:03 < misterhat> er what kind of game are you doing
00:05 < harrydog> multiplayer drawing game, i want people to choose a name, and start playing, but give them the option to "reserve" a username (which then they would need to create a password to log on, or save the session id in a cookie so they dont have to log in everytime)
00:05 < misterhat> why not just have a registration system
00:05 < misterhat> and use local storage
00:06 < harrydog> what do you mean, like registration page?
00:06 < misterhat> yeah but it doesn't have to be a different page
00:07 < harrydog> why would i use local storage over cookies, i would think cookies would be better because the sessionid would be sent to socket.io when the user connects automatically, without loading the local storage data and sending
00:08 < misterhat> well it's all under one page request
00:08 < misterhat> local storage is pretty similar to cookies just that it's not sent in each header
00:08 < misterhat> and can hold a lot more
00:12 < garbagecollectio> what is the absolute best tutorial on scaling node.js
00:13 < misterhat> i saw a pretty good conference video on it
00:14 < misterhat> but i'm the only one who likes conference videos
00:14 < codingstream> is anyone here using haibu on smartos?
00:15 < gkatsev> misterhat: I watch talks all the time
00:15 < misterhat> good gkatsev :P
00:15 < garbagecollectio> Hiredis?
00:15 < garbagecollectio> how does hiredis compile to C?
00:27 <@konobi> it's an addon
00:28 < Dan2928> Hi. I am creating a server with a text protocol. Acessible by telnet. Are there some module to help me with package fragmentation of the network connection ?
00:48 <@konobi> LeftWing: iirc destroy_zpools doesn't work anymore
00:48 <@konobi> bah
02:04 < mscdex> woohoo! read and write streams for sftp!
02:06 < drudge> nice
02:07 < MI6> joyent/node: Ben Noordhuis v0.8 * e5649d4 : tools: fix platform detection on freebsd, sunos  This is a back-port of u (+1 more commits) - http://git.io/A2OnOg
02:07 < pancake> is there any kind of backward compatibility module for iowatcher?
02:07 < pancake> im trying to use mdns module, but it's complaining about this all the time
02:09 < jrajav> Does anyone know if there's a way to make a mocha test that *passes* if it times out? I'm try to test that an asynchronous function does NOT call a certain callback (of several passed to it).
02:10 < mscdex> pancake: add your 2 cents to this issue: https://github.com/agnat/node_mdns/issues/34
02:10 < mscdex> pancake: gotta nudge them a bit :-)
02:10 < jrajav> As written, I'm calling done() on the happy path, and then done(new Error(..)) in the callback that should not be called. However, when I synthesize a failure, it fails the NEXT test in the suite with "done() called multiple times"
02:10 < jrajav> This is undesirable
02:24 < bsnote> How can I specify target endianness when cross-compiling node.js?
02:31 < fotoflo__> I'm using nodev to restart node and the inspector whenever i update filesâ€¦ is there a reason i have to refresh the inspector in my browser each time the inspector restarts on the server?
02:44 < graw1> i have stream of 64-bit double precision floating point number, can i read it without external lib?
02:50 < mscdex> graw1: buffer.readDouble()
02:50 < mscdex> graw1: http://nodejs.org/api/buffer.html#buffer_buf_writedoublele_value_offset_noassert
02:50 < mscdex> er
02:50 < mscdex> graw1: http://nodejs.org/api/buffer.html#buffer_buf_readdoublele_offset_noassert
02:53 < graw1> yep somehow missed that, thanks
03:05 < murtaza_> something
03:10 < warz> when using "npm test", can i pass options to the unit testing engine? this uses mocha, and i want to specify a timeout.
03:10 < warz> i could edit package.json, or the test code, but itd be nice if i could pass right through over command line
03:14 < dbounds> If anyone (in the US) is in the market for a FT node position (express), shoot me a mention on Twitter @dbounds. Great team, great pay/benefits, exciting, rapidly growing project/service.
03:17 < devinrhode2> how do I start node on a certain port?
03:17 < warz> start node on a port? sounds like youre asking about an http/tcp server?
03:17 < warz> it's just a parameter to the listen function.
03:18 < devinrhode2> from the command line
03:18 < warz> server.listen(80)
03:18 < devinrhode2> I remember there being an option like node server.js --port 80
03:18 < L10n> server.listen(process.argv[2])
03:18 < misterhat> i've never heard of it
03:18 < warz> im assuming thatd be an option in server.js.
03:18 < misterhat> doesn't show up on node -h either
03:18 < warz> it'
03:19 < warz> it's not an option
03:19 < warz> he's asking about node, but he's really meaning something like express or just a server of some kind. you'll have to look into the actual module you're using. if it's something installed globally, it may have a command line param.
03:19 < L10n> commander works good for building your own args
03:20 < devinrhode2> ah I am thinking of express.
03:36 < harth> is there an npm package that will take a directory and walk it recursively and give you a list of all the files in the directory?
03:37 < mscdex> probably at least a dozen
04:40 < _numbers> harth i like node-glob
05:13 < kenperkins> does anyone know if node's underlying network layer (when using tcp) screws with the http layer connection pool?
05:14 < freewil> have no idea - all i can say is that i think the http pooling is handled by whats called an http agent in the documentation
05:15 < kenperkins> yea I've read about that
05:15 < freewil> not sure what you're doing exactly with tcp but it seems node would be able to separate them out
05:16 < kenperkins> redis & riak
05:17 < kenperkins> when I do a test, using only riak, I see connection pooling as I expect.  but when I add a parallel codepath doing redis calls (which are tcp) the connection pool seems to go bonkers, and I end up with hundreds of connections
05:19 < freewil> seems more likely an issue with how the redis library is being used
05:19 < freewil> or the library itself
05:25 < kenperkins> possibly
05:25 < kenperkins> I'll try to isolate that later today
06:19 < _numbers> require() is telling me 'cannot find module' but i know its there. how can i ask require to list the paths its checking?
06:22 < _numbers> if i use the absolute path to the lib, it will require it. hmm how can i tell where its checking? its it based on process.cwd()?
06:24 < _numbers> i am calling require('node-gd') from ./node_modules/grunt-contrib-stylus/tasks/stylus.js and expecting it to find ./node_modules/stylus-lemonade/node_modules/gd/gd.js
06:43 < _numbers> DEBUG=* NODE_DEBUG=module   :)
06:55 < guybrush> hm _numbers try putting gd into ./node_modules
06:56 < guybrush> _numbers: http://nodejs.org/api/modules.html#modules_all_together
06:56 < _numbers> i figured it out. its named ./gd but i'm requiring 'node-gd'. a subtlely. perhaps because i am checking out from git repo directly 
06:56 < guybrush> _numbers: cool
06:56 < guybrush> that is a problem indeed didnt notice
07:06 < timoxley> anyone recommend an s3 uploader in node that has a command line utility?
07:08 < freewil> ive been using a perl based one, https://github.com/timkay/aws
07:08 < freewil> let me know if you find a good node one though!
07:09 < timoxley> freewil yeah I've been playing with that one, doesn't do auto mime type detection though 
07:30 < mix_> trying to figure out if node would be a good choice for my needs. is this a good place to ask a question like that?
07:30 < mix_> (with more specifics of course)
07:36 < xaka> mix_: sure it is, but probably everyone just asleep
07:36 < staar2> hello
07:37 < staar2> i can not getting work the formidable upload could anyone look whats wrong ? http://pastebin.com/1hdaZwvk
07:37 < felixge> staar2: you *must not* execute any middleware before this
07:38 < felixge> or it won't work
07:38 < felixge> (that's because otherwise formidable will not be able to get the first 'data' events from the req)
07:38 < felixge> specifically you must not execute any middleware that does something async
07:48 < mix_> saka, thx. i'll toss it out, see if it makes sense.  i want to build a simple web app where any number of clients can increment/decrement a number and that number (along with ID info) gets stored on the server.  then another app (or the same app) should be able to watch those stored numbers continously and spit out a web page that monitors the numbers in real time.  very simple stuff, but it could be a bunch of simultaneous clients (e.g.
07:48 < mix_> pushing this over cell data networks
07:48 < mix_> wondering if node.js is a good choice for something like this
07:53 < xaka> mix_: i see no reason why node.js wouldn't work here (or any other technology/language), it sounds simple. so if you want to learn node.js just go for it
07:54 < mix_> guess i'm trying to figure out if i need to go with a web app framework or if i can do this more simply, say with javascript writing to files on the server via ajax or something like that.  altho i keep hearing about node so that's prob what brought me here
07:58 < xaka> mix_: do you need the counter to be persistent like when you restart your service?
07:58 < mix_> possibly. i do want the data saved
08:02 < staar2> felixge, how to make sure that middleware is not executed ?
08:02 < xaka> mix_: i don't think you need framework if it's really as simple as you tell. node.js + sqlite or node.js + mongodb gonna do the work
08:02 < Technodrome> i still haven't got into node.js
08:03 < Funhouse> Hi there, just wondering what the best mysql library to use is?
08:04 < felixge> Funhouse: depends, but the "most used" is 'mysql'
08:04 < felixge> Funhouse: disclaimer: I'm the author
08:04 < felixge> ; )
08:04 < xaka> the first one in seach results :)
08:05 < Funhouse> felixge: ok awesome will be using it. Thank you!
08:05 < felixge> hf
08:06 < misterhat> felixge: hello authour of 'mysql'
08:06 < felixge> misterhat: hi ; )
08:07 < mix_> does mongodb only write binary json?  or can it work in ascii?
08:08 < misterhat> wat
08:08 < misterhat> i'm pretty sure it's bson only
08:08 < gildean> mix_: the data is bson, but that doesn't matter
08:08 < mix_> yah ok
08:08 < gildean> because your clients aren't going to connect to the database directly
08:09 < gildean> hopefully
08:09 < mix_> right
10:08 < Xix19> does using blocking functions affect the rest of the program?
10:10 < Xix19> If I have something like setInterval(function(){ console.info('abc'); }, 100); and then I do a synchronous I/O that takes 20 seconds, will the console still write 'abc' during that time?
10:10 < freewil> no
10:10 < Xix19> freewil: so blocking functions pause execution only on the current call stack?
10:11 < Xix19> oh, you saidno....
10:11 < freewil> it blocks the entire process
10:11 < Xix19> so it blocks the ENTIRE program
10:11 < freewil> yes that is why everything is asynchronous
10:12 < misterhat> everything except alert and it's friendly functions
10:12 < misterhat> its*
10:12 < freewil> you have some sync functions you can use but that is only suitable for single user programs or cronjobs or something
10:14 < Xix19> there's no way currently to do asynchronous callbacks without using messy callbacks?
10:14 < Xix19> and Promisses are just as messy
10:15 < freewil> you mean several nested levels?
10:15 < freewil> https://github.com/caolan/async
10:17 < Xix19> freewil: no, I mean how to do 10 mysql calls without having 10 callbacks?
10:17 < Xix19> a simple 10 linear calls to mysql
10:18 < freewil> async can make that easier
10:18 < freewil> you can do async.parallel
10:18 < Xix19> I'd have to nest it 10 levels deep, or create 10 functions
10:18 < freewil> or if they dependent on each other async.series
10:19 < Xix19> yeah but then I write 3 rows for each call, and I can't use whatever happens in the previous functions for the next ones
10:19 < Xix19> javascript is great, bu it could really use some "async"-like keyword to behave like yield for I/O
10:20 < freewil> meh
10:20 < freewil> people have made things to do that
10:20 < freewil> it's not that complicated really
10:20 < freewil> you make small functions that do one thing and chain them together with callbacks
10:22 < Xix19> yes but now you have 10 functions so bloated code, AND they can't interact with eahother since they're completely separated (a variable declared in one can't be used in another)
10:22 < freewil> Xix19, you're just not used to it
10:22 < freewil> you can create a variable outside the scope of the functions that they all can access
10:23 < Xix19> which leads to more redundant lines of code
10:23 < freewil> or take a look at async.waterfall for example where the results of one callback is passed to the next
10:23 < freewil> not really, it's akin to OOP where you have an instance variable
10:24 < Xix19> 10 mysql calls should take 10 lines. Doing it in any non-blocking way in node.js require 30+ lines and it's harder to maintain because of it's modular nature
10:24 < freewil> i have to ask what you're doing anyway if you're doing 10 queries
10:24 < freewil> that sounds pretty excessive
10:24 < felixge> Xix19: try Go : )
10:25 < Ezku> or scala, or...
10:25 < Xix19> I'm not, I'm just trying to learn the ps and downs of node
10:25 < Xix19> ups*
10:26 < freewil> well what you have to understand is that your node program is pretty much single-threaded, that is why you have to do everything non-blocking
10:26 < freewil> you can fork more processes, but with a single thread you avoid concurrency issues
10:26 < Ezku> Xix19: you can reduce the syntactical overhead a lot by using something like coffeescript, and promises are actually way awesome in the way they can be composed
10:27 < Xix19> the next ECMA version has yield. Yield rewrites the internal function (to a class or whatever) so it can block ONLY the current call stack
10:27 < Xix19> there is also a proposal to add the "async" keyword to function just like yield, but for I/O
10:28 < Ezku> one thing you can do is use something liked icedcoffeescript if you really, really want to have async stuff look like sync
10:28 < Xix19> so you can have linear coding patterns without blocking you whole process
10:29 < Xix19> I prefer to see what I write, cofeescript is a candy blind over my eyes
10:29 < Fike_> so, I managed to break my IRC parser
10:30 < freewil> so you only write in assembly eh?
10:30 < Ezku> I like to think CS is just another notation for JS, and it really doesn't get in the way
10:30 < Fike_> coffeescript sucks
10:30 < Xix19> freewil: heh
10:30 < Ezku> freewil: exactly, if you want to put it bluntly
10:30  * Fike_ hides
10:30 < Xix19> freewil: there's nothing wrong with candy, but too much will make you fat
10:32 < freewil> after using coffeescript for a while, i just dont want to go back to having to write out function, parenthesis, and braces
10:32 < freewil> it's just more fun
10:32 < Fike_> freewil: so, you're lazy? ;)
10:33 < freewil> efficient :)
10:34 < Xix19> when will yield be implemented for node.js?
10:34 < Xix19> javascript 1.7 has yield - https://developer.mozilla.org/en-US/docs/JavaScript/New_in_JavaScript/1.7
10:35 < Fike_> Xix19: if support isn't present in v8 yet, you'll have to wait for google to add support
10:35 < Xix19> go go google
10:40 < alchimista> hi, I am using mongoose with nodejs, and express js, I do a query but the sort doesnot work, any help? https://gist.github.com/d8991969903e8c2c715a
11:03 < gavri> I create promises in my code to process a bunch of files and create db records from them. seems like since these promises get created, on one tick and they are only executed on later ticks, I get a "maxBuffer exceeded" error.
11:03 < gavri> how do I work around this? what am I doing wrong here? and how do I fix this?
11:41 < turbolent> is there any way to create a context which also supports require?
11:42 < turbolent> passing require into vm.createContext will result in code being evaluated in the current context when require is called in the new context
11:56 < alchimista> hi everyone
11:56 < Kakera> out of curiosity, why does node.js bundle v8 instead of referencing the v8 git repo?
12:04 < alchimista> nodejs how to manipulate the result of mongoose find before rendering?
12:08 < mscdex> Kakera: easier, plus node has its own floating patches
12:09 < Kakera> what are these floating patches?
12:25 < alchimista>  how to manipulate mongoose result before rendering
12:27 < alchimista> no one to give me a hint?
12:31 < jden> hello room. offhand, does anyone know of a module to escape shell arguments?
12:48 < gildean> jden: what do you mean escape?
12:48 < gildean> jden: if you want to parse them easily, commander is an ok choice for that
12:48 < gildean> i'm sure there are others too
13:24 < bsnote> Hi, trying to cross-compile node.js for MIPS platform. I am using mips-linux-4.4-codesourcery toolchain:
13:24 < bsnote> $ export AR=mips-linux-gnu-ar
13:24 < bsnote> $ export CC=mips-linux-gnu-gcc
13:24 < bsnote> $ export CXX=mips-linux-gnu-g++
13:24 < bsnote> $ export LINK=mips-linux-gnu-g++
13:24 < bsnote> $ export RANLIB=mips-linux-gnu-ranlib
13:24 < bsnote> ./configure --without-snapshot --dest-cpu=mips --dest-os=linux --without-ssl
13:24 < bsnote> make
13:25 < bsnote> getting a bunch of errors like:
13:26 < bsnote> mips-linux-gnu/bin/ld: /home/simpletv/git/node/out/Release/obj.target/v8_base/deps/v8/src/bootstrapper.o: compiled for a little endian system and target is big endian
13:26 < bsnote> mips-linux-gnu/bin/ld: /home/simpletv/git/node/out/Release/obj.target/v8_base/deps/v8/src/bootstrapper.o: endianness incompatible with that of the selected emulation
13:28 < bsnote> Can anyone help?
13:36 < stoke> bsnote: architecture?
13:59 < Dani9282> Hi, someone knows a SQL lite module to windows ? 
14:15 < bsnote> stoke: MIPS 74Kc V4.12  FPU V0.0
14:16 < mscdex> Dani9282: sqlite3?
14:18 < mscdex> bsnote: did you try explicitly setting CFLAGS and CCFLAGS/CXXFLAGS?
14:23 < bsnote> mscdex: what should I set them to?
14:24 < mscdex> bsnote: well, any/all architecture, cpu, etc. flags
14:24 < abrkn> with monk (mongodb), findandModify({ remove: true }) leaves a doc with only _id in the collection? anyone tried this
14:24 < mscdex> bsnote: e.g. -march=..., -mcpu=..., etc
14:36 < razzle> hi.. i have a page that needs some initialization parameters, how would you code this?
14:36 < razzle> ie use initializatrion parameters first, then change them after user input
14:44 < bsnote> mscdex: thanks, I'll try
14:47 < ispinfx> list
14:47 < autoboxer> list
14:48 < MelkorNemesis1> list
14:59 < brahdude> Hey chaps, got a small question. Whats the best book for learning node.js?
15:02 < SomeoneWeird> brahdude, http://www.nodebeginner.org/
15:02 < brahdude> SomeoneWeird; thanks.
15:09 < Voting> SomeoneWeird: the other best node.js resources?
15:11 < Voting> Anyone, beside SomeoneWeird's recommendation, what should I read to get good in node.js? 
15:12 < deoxxa> Voting: make stuff, practice
15:12 < deoxxa> Voting: and learn to love http://nodejs.org/docs/latest/api/all.html - it's pretty much permanently open in my browser
15:14 < Voting> thanks! deoxxa, the best reasons to be coding in node.js? 
15:14 < deoxxa> well that's a hard question to answer
15:14 < deoxxa> an interest in javascript, or an interest in some specific node project are both good ways to keep motivated i guess
15:15 < Voting> for you, you are happy doing your server side programming in node.js generally? 
15:15 < yawnt> HEY DEOOXA
15:15 < yawnt> DEOXXA
15:15 < mscdex> Voting: fwiw there's also http://nodetuts.com http://nodeguide.com/ http://howtonode.org/
15:15 < deoxxa> herro yawnt
15:15 < yawnt> sup
15:15 < yawnt> you back in AU already?
15:15 < deoxxa> Voting: yep, nearly everything at work is node.js now for me
15:16 < deoxxa> yawnt: yep, just sat down in my room after getting back :3
15:16 < Voting> where do you work? 
15:16 < yawnt> nicee
15:16 < deoxxa> Voting: a small company in australia
15:16 < Voting> lol
15:17 < Voting> I figure, if I can get people good at programming in one langauge (javascript, haxe, clojusescript, and I can keep us all doing it both on client and server...  
15:17 < Voting> why not keep it simple and focused? 
15:17 < Voting> so that's why I'm interested in node.js. 
15:17 < mscdex> why not keep it node.js?
15:17 < mscdex> ;-)
15:17 < deoxxa> i've actually come to disagree with the "same language on the client and the server" argument
15:18 < yawnt> mscdex: cause cljs kicks js' ass
15:18 < yawnt> :D
15:18 < deoxxa> having the same language is cool, sharing some code between the two is cool, but it's not as seamless as people make out
15:18 < yawnt> jokes apart.. cljs in kinda cool really
15:18 < yawnt> *is
15:18 < deoxxa> anyone who thinks writing client side code and server side code are the same thing is horribly misguided
15:18 < Voting> anyone tried to use haxe in node.js programming?
15:19 < mscdex> never looked into it
15:19 < Voting> deoxxa: what is an example of what you are trying to say? 
15:19 < mscdex> or closurescript for that matter
15:20 < deoxxa> Voting: how do you mean?
15:20 < Voting> deoxxa: "anyone who thinks writing client side code and server side code are the same thing is horribly misguided" - examples?
15:20 < deoxxa> ah, i just see that mentioned annoyingly often in various places
15:21 < gildean> it's totally not seamless, if you have to work with a browser
15:22 < Voting> What would "seamless" look like?
15:22 < gildean> basically only some of the coding conventions and things like objects moved between the serverside and clientside remain the same
15:22 < gildean> which do make it easier
15:22 < SomeoneWeird> json ftfw
15:25 < Voting> gildean: much of your code does not port easily from one side to the other? 
15:26 < Voting> Is that your main complaint? 
15:26 < gildean> Voting: how would it?
15:27 < Voting> If I write some statistical function, gildean.... why would it not?
15:27 < gildean> some of it, of course, but mainly the server parts are meant just for the server
15:27 < deoxxa> Voting: most client side code is completely distinct from server side code
15:28 < Voting> deoxxa: not sure what you are saying. Do you mean that mostly what I want to do on the server I will not WANT to do on the client? 
15:28 < deoxxa> Voting: generally client side stuff has to worry about very different things (compatibility in multiple environments, different performance profiles, ui specifics, etc)
15:28 < deoxxa> server side code is nearly always only run in a single environment with very predictable properties
15:29 < deoxxa> so although you might be able to get some code from one side working on the other, it'll likely end up being inappropriately structured or written
15:29 < gildean> also large parts of the client side js have to do with dom, which you fortunately rarely have to handle on the servers side
15:30 < deoxxa> you can still get a lot of code reuse, but it's not as close to 100% as it sounds when people say "it's the same language on both sides"
15:30 < gildean> there are of course some modules/libs that work very nicely on both sides
15:30 < gildean> like for example moment.js
15:30 < deoxxa> ^^ yep
15:30 < mscdex> there are some "plain javascript" stuff that can be shared on both sides, like data validation functions, game logic, etc
15:30 < mscdex> printf implementations
15:30 < mscdex> other utility functions
15:31 < mscdex> data structure implementations
15:31 < mscdex> :-)
15:31 < Voting> people like http://momentjs.com/ ? 
15:32 < SomeoneWeird> moment is amazing :)
15:32 < gildean> Voting: yeah, it's a great library
15:32 < gildean> or module
15:32 < Voting> other fav js libs? 
15:33 < Voting> (I'm really liking knockoutjs but I don't have much in the JS world to compare it to.)
15:33 < Voting> knockoutjs needs better tutorials to help people understand how to use it well... 
15:34 < Voting> but it IS very powerful.
15:36 < Voting> In the java world, I depend on http://cayenne.apache.org/ for object to relational mapping. What are  my best options in javascript? 
15:38 < Voting> are there really good object to relatinal mapping libs I should know about? 
15:40 < autoboxer> is Knockout.js a substitute for Backbone.js?
16:10 < dileep> i got some error in ma code like app is node deffined
16:10 < dileep> could anbody help me '
16:10 < dannymick> can you copy and paste the error?
16:11 < dileep> dileep@dileep-VirtualBox:~/authentication$ node app.js  node.js:201         throw e; // process.nextTick error, or 'error' event on first tick               ^ ReferenceError: app is not defined     at Object.<anonymous> (/home/dileep/authentication/app.js:6:1)     at Module._compile (module.js:441:26)     at Object..js (module.js:459:10)     at Module.load (module.js:348:31)     at Function._load (module.js:308:12)     at Array.0 (modu
16:12 < dyzastrus> We'll probably need to see the code to help with that. Can you paste bin it?
16:12 < dileep> dyzastrus:i already paste iit
16:13 < dileep> var express = require('express')    , routes = require('./routes')    , fs = require('fs');  //Routes app.get('/', routes.index); app.get('/form', function(req,res) {    fs.readFile('./form.html', function(error ,content)   {     if(error)     {       res.writeHead(500);       res.end();     } else  {    res.writeHead(200, {'Content-Type': 'text/html'});    res.end(content , 'utf-8');  } }); });
16:13 < dyzastrus> add var app = express();
16:13 < dyzastrus> after require('express');
16:15 < dannymick> yeah, what dyzastrus said. app is not defined
16:16 < dileep> Thankx,it works..
16:54 < crygin> hello to all
16:54 < crygin> can anybody help me with big integers in node?
16:55 < crygin> have node uint64_t equivalent?
16:56 < ciao> ciao 
16:56 < ciao> !list
16:56 < djazz> crygin: you have doubles http://nodejs.org/api/buffer.html#buffer_buf_writedoublele_value_offset_noassert
16:57 < djazz> or typed arrays?
16:57 < djazz> Float64Array
16:58 < djazz> hmm, no 64-bit integers though
17:00 < djazz> anyone know how I can zip files in nodejs? I tried using spawn to use the zip command, but some files causes the file to be corrupt
17:00 < djazz> file = zip output
17:00 < crygin> @djazz, i want to implement c function: https://gist.github.com/4189821 
17:02 < crygin> djazz https://github.com/daraosn/node-zip
17:03 < djazz> crygin: it dont use zlib module, lol
17:03 < djazz> :P
17:04 < crygin> djazz: https://npmjs.org/package/adm-zip
17:05 < crygin> https://github.com/rubenv/zipper
17:07 < djazz> ok, it was working with the zip command, the problem lies elsewhere
17:14 < djazz> when i send binary data to another node process (a fork), it gets the wrong length
17:14 < djazz> does it encode it or smth?
17:28 < gavri> does calling require() multiple times actually execute the definitions in it multiple times? I thought it didn't, but that's how it seems to be working in my test. console.log() statements are being executed more than once
17:29 < dyzastrus> gavri: it's not supposed to, but I've found that sometimes it does
17:35 < timeturner> gavri: require() caches
17:35 < gavri> dyzastrus, timeturner: thanks
17:36 < timeturner> but you have to realize that when the export of the module being required is a new instance of something then it may seem like it is executing it multiple times
17:36 < timeturner> for example: module.exports = new Something();
17:37 < dyzastrus> timeturner: in that scenario, it should return the same object though, no?
17:39 < djazz> i "solved" the issue by doing everything in the main process, sending binary data as strings seems glitchy in node
17:40 < djazz> now i get the correct length
17:42 < mscdex> djazz: huh?
17:42 < mscdex> use a Buffer?
17:44 < djazz> mscdex: strings only
17:45 < mscdex> buf.toString('binary') then ?
17:45 < djazz> i tried
17:45 < djazz> even in fork options {encoding: 'binary'}
17:45 < mscdex> and on the receiving end you did `new Buffer(str, 'binary')` ?
17:45 < djazz> yes
17:45 < djazz> i tried utf8 too
17:45 < djazz> and 'hex'
17:46 < gavri> grunt doesn't seem to work for my async tasks to complete. is that how it is supposed to work?
17:47 < djazz> mscdex: u know why 'binary' have "This encoding will be removed in future versions of Node." in it's description? it's very useful for... ehm.. binary data
17:47 < mscdex> djazz: it takes up more memory
17:48 < mscdex> for one thing
17:48 < mscdex> iirc
17:48 < mscdex> but i agree that the 'binary' encoding is still useful in some situations
17:49 < djazz> for example
17:49 < djazz> when getting onData events from zip's stdout
17:49 < djazz> i just use data += msg.toString('binary')
17:49 < djazz> could i replace that with utf8?
17:50 < djazz> and then use new Buffer(data, 'utf8')?
17:50 < owen1> gavri: grunt can handle async.     var done = this.async();
17:50 < mscdex> no, don't use utf8 for binary data
17:50 < owen1> gavri: http://robdodson.me/blog/2012/11/29/asynchronous-grunt-tasks/
17:50 < djazz> whats the best way for streaming onData until onEnd to get a buffer of all data?
17:51 < gavri> owen1: thanks
17:51 < mscdex> djazz: why not use a plain child process and write to stdin, that way you can use a Buffer
17:52 < mscdex> i don't know why the encoding thing is a problem though
17:52 < mscdex> for the .send()
17:52 < AAA_awright> Argh, why do all the crappy coders have to have the well-used modules
17:52 < AAA_awright> Or at least the package names
17:52 < djazz> mscdex: i sent the buffer from the child inside an object, it gets stringified internally
17:53 < djazz> {data: myBuffer, filename: 'files.zip'} etc..
17:53 < gildean> AAA_awright: why not try to fix the bad modules and make pull-requests?
17:53 < mscdex> djazz: what exactly are you trying to do anyway?
17:53 < AAA_awright> I am... It's consuming a few days of my time now
17:54 < djazz> mscdex: zip some files, in another process, using zip command (spawn), send back to browser (xhr request)
17:54 < djazz> the browser request what files on the server to zip
17:54 < gildean> AAA_awright: excellent, thanks for your involvement from all of us
17:54 < mscdex> djazz: why not just use the unix zip command directly?
17:55 < AAA_awright> Hint, guys: (typeof x==='object' && x instanceof Date) is redundant
17:55 < djazz> spawn('zip', args...);
17:55 < djazz> i AM
17:55 < mscdex> then why are you trying to use node's IPC to talk to it?
17:55 < djazz> hm?
17:55 < AAA_awright> (assuming x is somewhere in the scope, which it is inside a function call)
17:55 < mscdex> you're sending json to it
17:56 < mscdex> that's what i don't understand
17:56 < djazz> i dont use the zip command to make a file on disk, i want it to make a zipfile to a buffer
17:57 < djazz> i need to use json as I want to send back a filename and an error property, if errors occur
17:57 < mscdex> djazz: can't you just stream the result from zip back to the browser?
17:57 < djazz> i want a progress bar in the browser...
17:57 < djazz> if its a big file
17:57 < djazz> (content-length, before sending data)
17:58 < mscdex> ok, so then zip to disk and stream from the file?
17:58 < djazz> :P
17:59 < djazz> how can i concatenate two buffers easily/in best way?
17:59 < djazz> right now: new Buffer(header.toString('binary')+file.toString('binary'), 'binary')
17:59 < mscdex> Buffer.concat([buf1, buf2]) is the easiest....
17:59 < djazz> ah
18:00 < djazz> never seen that before
18:00 < mscdex> you can supply a total length as the second argument if you know it ahead of time
18:00 < mscdex> saves some calculation
18:04 < djazz> 255 ms to compress and send 5 MB
18:07 < timeturner> djazz: how so?
18:07 < timeturner> 255ms to send 5 MB :O
18:07 < timeturner> damn
18:08 < mscdex> djazz: also, you might be able to use something like pv to monitor progress for streaming a zip file
18:08 < owen1> i don't understand this for loop syntax - http://pastebin.com/vahW9s0P can someone explain what's going on there?
18:09 < djazz> timeturner: yea, i do some DB lookups too, to check if user supplied correct username/password combination
18:09 < djazz> lookup*
18:09 < timeturner> owen1: iteration over an object
18:10 < timeturner> for( key in object)
18:10 < mscdex> owen1: it's using a closure to capture the value of actions[i]
18:10 < djazz> and parsing the POST data using formidable
18:10 < mscdex> owen1: i'm not sure why they're doing that when there is no async callback in there
18:10 < mscdex> owen1: that's generally when you need to do that sort of thing
18:11 < owen1> mscdex: i want to help a friend refactor his first npm package
18:11 < owen1> mscdex: how would u re-write that?
18:11 < owen1> mscdex: timeturner here is the complete file - https://github.com/djvirgen/virgen-acl/blob/master/lib/acl.js
18:12 < mscdex> owen1: something like this?: https://gist.github.com/4d8e689c2f33b67474b7
18:12 < mscdex> although i'm not really a fan of `for (var x in foo)`-style for-loops
18:13 < owen1> mscdex: your version looks so simple. what style would u use instead of for (var x in foo)
18:13 < mscdex> owen1: i'm a sucker for the plain for-loop: `for (var i = 0, len = actions.length; i < len; ++i) { /* something */ }`
18:14 < owen1> got it
18:14 < mscdex> but yeah, creating closures in loops like that where they're not needed is just adding more overhead
18:16 < mscdex> owen1: also, their getParentResources function has a bug i believe: it's adding 'resource' twice
18:17 < owen1> mscdex: line 83?
18:17 < mscdex> 73
18:18 < mscdex> they add it there, and then add it again on the first iteration of the loop
18:19 < mscdex> also, it looks like they're doing a hierarchal thing. it might be worth using a real b-tree or something instead
18:25 < owen1> mscdex: awesome feedback. can u show me an example where creating a clojure is needed?
18:27 < mscdex> owen1: if you are doing something async inside the loop
18:28 < mscdex> owen1: and your callback references say `actions[i]`
18:28 < mscdex> owen1: by the time the callback is executed, it `actions[i]` won't be what you expect
18:28 < mscdex> owen1: that's when you need to capture the current value of `actions[i]` by way of a closure
18:29 < gavri> I tried the var done = this.async() way of getting grunt to wait till the async task is complete, but it seems to quit at arbitrary times and not wait till done() is called. any idea what might be going wrong?
18:30 < owen1> gavri: did u pass the done to your functino?
18:30 < gavri> owen1, yeah
18:30 < owen1> mscdex: thanks
18:30 < gavri> but it seems to be quitting before done() gets called
18:30 < gavri> at least based on the log statements
18:31 < owen1> gavri: paste the code
18:33 < vitsaus> i sit :/
18:33 < vitsaus> whops. wrong channel. with a typos
18:34 < gavri> owen1: http://paste.org/58074
18:38 < garbagecollectio> yo
18:39 < garbagecollectio> node.js cluster?
18:39 < garbagecollectio> what is the point of putting it on multiple cores
18:40 < owen1> garbagecollectio: each core can run a node process. it helps you scale your app
18:40 < garbagecollectio> but then how do you manage the interaction
18:40 < garbagecollectio> and is node by default assigned to a particular processor?
18:41 < gavri> owen1: is there anything obviously wrong with that code?
18:41 < dileep> node.js:201         throw e; // process.nextTick error, or 'error' event on first tick               ^ Error: Missing hostname.     at NativeConnection.open (/node_modules/mongoose/lib/connection.js:198:16)     at Mongoose.connect (/node_modules/mongoose/lib/index.js:150:15)     at connect (/home/dileep/authentication/lib/db.js:18:13)     at Object.<anonymous> (/home/dileep/authentication/lib/db.js:12:1)     at Module._compile (module
18:42 < owen1> gavri: do u call done somewhere? i see that u pass it, you got to call it eventually inside the function you'r passing it into.
18:42 < dileep> i got this error
18:42 < dileep> could anybody tell mme plzzz
18:42 < timeturner> missing hostname
18:42 < gavri> owen1: writeFile should call it
18:42 < gavri> th
18:42 < gavri> actually, what would happen if it's never called?
18:42 < gavri> when would grunt know that the task is done?
18:43 < dileep> var mongoose  = require('mongoose'); var Schema = mongoose.Schema;  module.exports.mongoose = mongoose; module.exports.Schema = Schema;  //Connect to cloud database  var username = "Dileep" var password ="******"; var address ='@ds043917.mongolab.com:43917/erp'; connect();  //connect to mongo function connect()  {     var url ='mongodb:// mongolab.com/databases' + 'Dileep' +':' + '*******' +'@ds043917.mongolab.com:43917/erp';    mongo
18:43 < dileep> that ma code
18:43 < dileep> where should i have to include host name
18:43 < garbagecollectio> huh
18:43 < garbagecollectio> http://username:password@hostname
18:44 < owen1> gavri: https://github.com/yp-engineering/engineering-website/blob/master/rss.js
18:44 < dileep> what nd where i was gone wrong
18:44 < owen1> garbagecollectio: in line 43 u see the last argument?
18:44 < garbagecollectio> i dont have the code
18:44 < owen1> i call cb in line 79
18:45 < owen1> gavri: ^^
18:45 < owen1> garbagecollectio: sorry, ignore that
18:45 < garbagecollectio> owen1 how is node on a single core?
18:45 < garbagecollectio> it defaults toa  single core?
18:45 < garbagecollectio> how do u assign it to a different core
18:45 < aho> it's single threaded
18:46 < aho> if you want to use more than one core, run more than one instance
18:46 < garbagecollectio> its single threaded cause javascript is single threaded
18:47 < aho> yes
18:47 < garbagecollectio> how cna javascript be single threaded
18:47 < dileep>  	git://gist.github.com/4190389.git please tell me what wrong in thhis beacause i gogt error for the Missing hostname
18:47 < garbagecollectio> a language can be single threaded? its not at the interpreter level
18:47 < gildean> yes and no, there's nothing in the language that would make it singlethreading on multithreading
18:48 < garbagecollectio> right
18:48 < garbagecollectio> but if u are single threaded you have to use one core?
18:48 < aho> well, there is no way to spawn threads/fibers/isolates/whatever
18:48 < garbagecollectio> if you are multithreaded do u have to use multiple cores?
18:48 < aho> therefore it's single-threaded
18:48 < garbagecollectio> or cna u do multithread on one core
18:49 < aho> you can run several threads on one core
18:49 < garbagecollectio> right so what is the purpose of having a node app attach to multiple cores?
18:49 < stagas> dileep: where do you think it's wrong?
18:49 < sorella> garbagecollectio, well, languages might be designed to be single or multi-threaded. JavaScript is not quite one of those.
18:49 < aho> right now, there are 562 threads running on my dual core machine
18:50 < garbagecollectio> having a node master app on one core and then "worker" aps
18:50 < garbagecollectio> what do these mult
18:51 < garbagecollectio> worker apps do
18:51 < dileep> stagas,i put the url field
18:51 < garbagecollectio> is it as simple as requests come into the master app on one core
18:51 < garbagecollectio> and then logic cna be spread around to different cores
18:52 < garbagecollectio> or routes can be sent
18:52 < garbagecollectio> what is the best most comprehensive node tutorial from intermediate to advance
18:53 < mscdex> garbagecollectio: the api docs and the tests?
18:53 < stagas> dileep: a typical url with authentication looks like this: protocol://username:password@hostname.com/path
18:54 < mscdex> and the source code
18:54 < garbagecollectio> is it as simple as requests come into the master app on one core
18:54 < garbagecollectio> and then logic cna be spread around to different cores
18:54 < garbagecollectio> like why would u have worker nodes
18:54 < garbagecollectio> and a master node
18:54 < dileep> ok,got that thankx,stagas
18:54 < garbagecollectio> and then workers on different cores
18:56 < garbagecollectio> why is javascript synchronous
18:56 < garbagecollectio> but node.js is asynchronous
19:06 < mscdex> garbagecollectio: node.js provides async i/o, the code itself is synchronous
19:06 < mscdex> just like any code
19:09 < AAA_awright> It's rather misleading to say code is "synchronous" or "asynchronous" in any event
19:09 < garbagecollectio> how can node.js be single threaded application
19:10 < garbagecollectio> if it puts functions into memory and can continue executing the coe
19:10 < AAA_awright> It might be flow/stream programming (which ECMAScript is not)
19:10 < garbagecollectio> if its asynchronous
19:10 < _numbers> so if i am working on a project where i need to modify a lot of the node_module/ dependencies, whats the best way to package that all under the same repo? i dont want to have to fork and link at every package from packages.json unless i have to
19:10 < _numbers> i am thinking about using `npm link` and creating a subdirectory within the main repo that holds a snapshot of the dependencies i have modified. is this common practice? any convention around this?
19:10 < AAA_awright> garbagecollectio: It's called an event loop. Wait until something happens, then process that event, rinse, repeat
19:11 < AAA_awright> All events that have to wait on I/O are implemented like this.
19:11 < garbagecollectio> but meanwhile its waiting and also can execute other code
19:12 < garbagecollectio> which is basically done by threading
19:12 < AAA_awright> garbagecollectio: It's not waiting as such. When the data is returned from disk, or the network, it'll fire an event on the event loop.
19:12 < AAA_awright> And that event will be processed at next loop iteration
19:12 < mscdex> it's synchronous in that the instructions are running on one core in order
19:13 < AAA_awright> garbagecollectio: You're just declaring "Get X data from disk, and when the event loop gets that data back, this is the function it should call"
19:14 < garbagecollectio> but then how is the other code being run
19:14 < garbagecollectio> not the callback
19:14 < garbagecollectio> but the next function
19:14 < garbagecollectio> and why is node.js like this
19:14 < AAA_awright> What next function?
19:14 < garbagecollectio> well if you have an app
19:14 < garbagecollectio> and say u have to get stuff from the database
19:14 < AAA_awright> *you
19:15 < garbagecollectio> and then you try to get that data before the function returns
19:15 < garbagecollectio> it will execute it all
19:15 < garbagecollectio> i mean in node
19:15 < garbagecollectio> if you have a(); b();
19:15 < garbagecollectio> it will run a and then run b
19:15 < warz> libuv does use a thread pool
19:15 < garbagecollectio> even if a isn't done
19:15 < AAA_awright> warz: It doesn't have to
19:16 < AAA_awright> It's a hack around stuff but that's unimportant
19:16 < Mortchek> garbagecollectio, a has to finish before b executes. That's how JS works.
19:16 < garbagecollectio> no it doesnt though
19:16 < Mortchek> garbagecollectio, but the consequences of a, such as asynchronous callbacks, aren't necessarily confined to a.
19:16 < AAA_awright> Yeah it does?
19:16 < garbagecollectio> there are tons of "rrace conditions"
19:16 < garbagecollectio> what? B can totally get executed before A finishes?
19:16 < Mortchek> garbagecollectio, no it can't.
19:16 < garbagecollectio> that happens all the time
19:16 < AAA_awright> garbagecollectio: b won't be called until a has finished executing
19:17 < garbagecollectio> that is completely wrong
19:17 < AAA_awright> Uhhhhh
19:17 < AAA_awright> How
19:17 < Mortchek> garbagecollectio, show me an example where you think b starts before a finishes.
19:17 < warz> garbagecollectio, i think youre confused about callback functions?
19:17 < garbagecollectio> in node.js?
19:17 < Mortchek> garbagecollectio, sure.
19:17 < garbagecollectio> i mean almost any function
19:17 < garbagecollectio> that has a callack
19:17 < garbagecollectio> say a database get
19:17 < Mortchek> garbagecollectio, one example is all that is needed.
19:17 < AAA_awright> garbagecollectio: The callback isn't being executed. It's just being defined.
19:18 < warz> i think he's confused about this: foo(function bar() { ... }); baz();
19:18 < AAA_awright> And now that it's defined, it can be used at a later iteration of the event loop
19:18 < Mortchek> My statement is: b never starts before a finishes. To disprove that, you just need one counterexample. (You won't find one, but I can still show you where your misconception is.)
19:18 < _numbers> is there an easier way than this to work on a collection of custom and modified dependencies with a team of other node devs? http://www.hastebin.com/libiyalefu.vhdl
19:19 < garbagecollectio> collection.find({ key: value}, function(err, data) { console.log(data) }); b();
19:19 < gavri> owen1: debugging this is painful because for some reason console.log never works from grunt tasks. any idea why?
19:19 < AAA_awright> garbagecollectio: It calls collection.find(...);, then b();. "function(err, data) { console.log(data) }" is not being executed.
19:19 < warz> garbagecollectio, b is not called until find is completed.
19:20 < dinoxyz> hi
19:20 < garbagecollectio> um
19:20 < garbagecollectio> guys
19:20 < Mortchek> garbagecollectio, the call to collection.find just says "I want you, at some point after this function is done executing, to call my callback once you've found the thing I'm looking for".
19:20 < garbagecollectio> in node.js this happensa ll the time
19:20 < garbagecollectio> right
19:20 < Mortchek> garbagecollectio, that is its only action. It doesn't do the actual finding yet.
19:20 < garbagecollectio> in the meantime, B gets executed
19:20 < Mortchek> So it's done.
19:20 < mscdex> node is only ever executing one block of code at a time
19:20 < garbagecollectio> ok
19:20 < garbagecollectio> wait a second
19:21 < garbagecollectio> your defining function execution as  "I want you, at some point after this function is done executing, to call my callback once you've found the thing I'm looking for".
19:21 < garbagecollectio> but not the actual action of finding the thing?
19:21 < Mortchek> garbagecollectio, no, that is what collection.find does (I'm assuming).
19:21 < Mortchek> garbagecollectio, collection.find is done as soon as it tells the environment to do that thing later.
19:21 < warz> garbagecollectio, collection.find does some stuff that you dont see. when its done, it calls the function you passed in as a parameter.
19:22 < garbagecollectio> yes i know this
19:22 < AAA_awright> garbagecollectio: First, collection.find() is executed. This means "send a query to the database server, and call this other function {here} when it's completed". Then b() is executed. Then, when the query is complete, that fires the event loop, and your other function is called with the result.
19:22 < warz> doesnt even have to been when its done. thats just what im assuming its doing.
19:22 < garbagecollectio> yes!
19:23 < garbagecollectio> AAA_awright: yes
19:23 < garbagecollectio> exactly
19:23 < AAA_awright> So what's the hangup then?
19:24 < garbagecollectio> the hangup is that this requires some sort of 
19:24 < garbagecollectio> threadedness
19:24 < Mortchek> No it doesn't
19:24 < Mortchek> If b takes forever, the request never happens
19:24 < Mortchek> Because nothing else can execute until b finishes
19:24 < garbagecollectio> if b errors out u think collection.find() won't finish?
19:24 < garbagecollectio> no
19:24 < AAA_awright> garbagecollectio: Once all your functions in that iteration of the event loop are called, and only when that's all finished, can the operating system begin working on your query
19:24 < Mortchek> If it errors out, no problem - it didn't take forever
19:25 < garbagecollectio> b doesnt have to be done
19:25 < garbagecollectio> for the callback to be made
19:25 < Mortchek> Yes it does
19:25 < AAA_awright> garbagecollectio: The callback can only be made on a new iteration of the event loop. That won't happen until ALL of your code is done executing
19:25 < Mortchek> garbagecollectio, try this: run an infinite while loop immediately after collection.find and see if the callback is ever called.
19:25 < AAA_awright> ^^
19:26 < AAA_awright> garbagecollectio: Your code is never interrupted in the middle of processing, ever
19:26 < AAA_awright> Due to the event loop it must wait until your code is done, and waiting on a new event from the event loop
19:26 < garbagecollectio> so the "async" stuff is really the callbacks don't get called until the main app, or what is in the global space is complete?
19:27 < AAA_awright> That's what async means, yes
19:27 < AAA_awright> I think?
19:27 < garbagecollectio> wow
19:27 < Mortchek> For Node in particular, the main module itself runs and sets everything up; then, the program continues running as long as events are being looked for
19:27 < Mortchek> or until it's told to exit
19:27 < garbagecollectio> now why would anyone have that arrnagement
19:27 < AAA_awright> async means you're specifying a function to be called later, so other I/O calls may be made in the meantime
19:27 < _numbers> managing dependencies in node is harder than ruby i guess because bundler makes a master list of all gems at various versions in a single ~/.rvm/gems/ruby*/bundler/gems/ directory. where npm scatters them throughout various ./node_module/ subdirectories. so if i just want to patch a certain version of a dependency in a large project, i have to do it in many places. but with bundler i only have to do it in one place.
19:28 < sorella> garbagecollectio, because it makes sense for I/O bound stuff.
19:28 < garbagecollectio> what is i/o bound stuff
19:28 < sorella> garbagecollectio, and it's the simplest ever model for concurrency in imperative/impure languages like JavaScript or Java.
19:28 < AAA_awright> Things where your bottleneck is in I/O requests, instead of CPU processing
19:28 < AAA_awright> It's also really dead simple
19:29 < AAA_awright> (Threads are nasty and complex compared to event loops)
19:29 < Mortchek> Notice that in JS you don't need to use locks and such
19:29 < Mortchek> Because only one function executes at once
19:29 < AAA_awright> (Not to say that race conditions are impossible, but you just don't need locks)
19:29 < garbagecollectio> AAA_awright: you mean the fact it is async reduces load on the CPI?
19:29 < sorella> AAA_awright, threads are only complex in impure languages. They are a joy in pure ones.
19:30 < AAA_awright> sorella: Because it's all abstracted away, that doesn't make the program any less complex
19:30 < Mortchek> sorella, threads are essentially transparent in pure computations, no?
19:30 < AAA_awright> Try working in a dataflow language
19:30 < sorella> Mortchek, the compiler can do the multi-threading stuff for you.
19:31 < garbagecollectio> sorella, what does that mean simplest ever model for ocnsurenncy
19:31 < sorella> AAA_awright, okay, so pure, functional languages like Haskell*
19:31 < AAA_awright> garbagecollectio: I/O bound applications are those that spend the majority of their time waiting on I/O operations. Like database queries.
19:31 < sorella> I've never worked with dataflow, so can't really say anything on that topic.
19:32 < AAA_awright> Also stuff designed for it like Haskell I guess, note that there's a ton of stuff which depends on the compiler being smart enough to figure out how to code
19:32 < AAA_awright> er, logic-ize, uh, optimize
19:32 < Mortchek> Optimization should be the compiler's job anyway, not the programmer's
19:33 < AAA_awright> Except that optimization is mathematically hard
19:33 < garbagecollectio> so how does this model 
19:33 < Mortchek> We still have to optimize when it matters because compilers aren't smart enough
19:33 < garbagecollectio> result in 
19:33 < garbagecollectio> node being able to handle 100,000 requests
19:33 < garbagecollectio> just by its nature of being 
19:33 < AAA_awright> Optimization isn't really that different than, say, symbolic integration
19:33 < garbagecollectio> asyncronous
19:34 < Mortchek> On the other hand, optimization can be defeated by the very nature of your algos
19:34 < Mortchek> It's hard for a compiler to take an O(n^2) sort down to O(n log n)
19:35 < AAA_awright> That's what I'm talking about, even the sort example
19:35 < niggler> any simple demo for setting up a private NPM repo?
19:35 < AAA_awright> Different sorting algorithms have different worst-case performance which makes a difference if the data that's coming in is already sorted or already random
19:36 < garbagecollectio> isnt there a new 
19:36 < AAA_awright> But the compiler has no clue if the data is going to be sorted or random
19:36 < garbagecollectio> isnt there something from google which reduces overhead
19:36 < garbagecollectio> on v8
19:36 < Mortchek> AAA_awright, it probably helps if we're allowed to give the compiler hints
19:36 < Mortchek> (Even if not much)
19:36 < garbagecollectio> and why does v8 interpreter spawn 2 million JS objects for idle garbage collection
19:36 < garbagecollectio> This was critical, as the server pre-allocates over 2 million JS Objects for the network topology. If you donâ€™t disable idle garbage collection, youâ€™ll see a full second of delay every few seconds, which would be an intolerable bottleneck to scalability and responsiveness. 
19:36 < AAA_awright> Well yeah, so you end up having a library of different functions, usually, for all the different worst-case scenerios
19:37 < Mortchek> e.g., "Hey compiler, this data is probably already mostly sorted. Just so you know."
19:37 < sorella_> type annotations for sorted/unsorted data
19:38 < garbagecollectio> how does aynchronous result in lower CPU
19:38 < sorella_> sort-stuff :: MostlySorted [a] â†’ Sorted [a]
19:38 < garbagecollectio> and transfers bottlenecks to code
19:38 < garbagecollectio> ?
19:39 < Mortchek> sorella_, I would dispute that being a *type* annotation. You're still operating on lists either way
19:39 < garbagecollectio> concurrency
19:39 < Mortchek> Well
19:39 < sorella_> Mortchek, IO.
19:39 < MelkorNemesis> hey guys, just curious, do you develop applications only in node.js at the moment? I mean if you omit php at all, because node.js is so powerful
19:39 < MelkorNemesis> or any other language (python, ruby..)
19:40 < Mortchek> sorella_, in what way does that represent a type?
19:40 < MelkorNemesis> or do you use node.js as a service for some particulars things in your php applications?
19:41 < djazz> MelkorNemesis: node.js only, sometimes a web interface with xhr/websocket/http communication
19:42 < MelkorNemesis> djazz: and before that you were a php(ruby, python) developer?
19:42 < djazz> php
19:42 < Mortchek> sorella_, hmm, I can see how sorted list can be a type - you eliminate all the unsorted values from the larger list type. What about mostly sorted? That's the same size as list, theoretically.
19:42 < djazz> i made similar stuff in php, like socket servers
19:42 < djazz> but it was horrible ):
19:42 < MelkorNemesis> thanks, cause I am thinking about getting more into node.js and omitting php
19:42 < Mortchek> sorella_, or rather, it contains all the same elements as list. (They'd be the same size anyway.)
19:42 < sorella_> MelkorNemesis, most languages.
19:42 < djazz> MelkorNemesis: what will you make?
19:43 < sorella_> Mortchek, that could be just a tag/hint to the compiler, not necessarily meaning a structural difference.
19:43 < sorella_> A structural difference in the [a] type, that is.
19:43 < MelkorNemesis> djazz: well, I have few projects and one of them is based on communication (chat) so there node.js  and sockets come handy
19:43 < Youdaman> MelkorNemesis: I used to code in Perl/Python, then PHP, now moved to JavaScript. First language was C++. I'm thinking Node is the way of the future -- re PHP, it will remain for a while, but I think the LAMP stack will be overtaken by either Node or something else
19:43 < MelkorNemesis> djazz: they are just in proposal state now
19:43 < djazz> k
19:43 -!- mode/#node.js [+o piscisaureus_] by ChanServ
19:43  * sorella_ hopes it's Clojure.
19:44 < MelkorNemesis> Youdaman: i've been programming in php for 7 years and I use Nette framework, which is very brilliant, but still node.js has its magic
19:45 < vro> what about node for general web apps, something you don't particularly need live chat etc for
19:45 < MelkorNemesis> well I am curious about that too
19:46 < djazz> node-webkit is kinda awesome
19:46 < djazz> :D
19:46 < sorella_> vro, which kinds of applications?
19:46 < AAA_awright> MelkorNemesis: Strictly speaking Node.js is more than just async I/O, relying lots on ECMAScript's object model
19:46 < djazz> making desktop apps with node
19:46 < Mortchek> I may be mistaken, but isn't Node strictly more powerful than PHP? Node has a continuous process, not one that handles a request then quits.
19:46 < sorella_> The v8 engine is also tons faster than any PHP engine, afaik.
19:46 < AAA_awright> PHP doesn't have first-class functions or function closures (real closures that have an independent variable scope)
19:46 < Mortchek> Or can PHP be configured to do that too?
19:46 < vro> i don't really have an example.. say like an online store
19:47 < sorella_> Also, the language is much better all around.
19:47 < Youdaman> MelkorNemesis: frameworks ftw :) As much as PHP gets a bad rap, it's behind a lot of cool things. The benefit to Node as I see it is I can run a program and it acts as the server as well as the app, i.e. no need for Apache like you'd use to run your PHP
19:47 < MelkorNemesis> well, that's what chase me in PHP, every request is new instance of "server"
19:47 < MelkorNemesis> Youdaman: exactly!
19:48 < AAA_awright> There's not much distinction, really
19:48 < AAA_awright> PHP handles HTTP requests, Node.js handles HTTP requests
19:48 < AAA_awright> The difference is one listens as a server
19:48 < AAA_awright> because the difference is one is evented and the other is synchronous
19:48 < Youdaman> MelkorNemesis: and the whole event-driven thing is appealing re handling more hits
19:48 < djazz> with node, you write your own webserver. php uses an existing
19:49 < Mortchek> You don't even have to write one yourself - there are modules for that
19:49 < djazz> :P
19:49 < MelkorNemesis> :)
19:49 < sorella_> You could probably write your own webserver in PHP as well.
19:49 < Mortchek> I think one of the more appealing things about Node is the module ecosystem
19:49 < AAA_awright> It's possible to write your own HTTP daemon in PHP and handle the HTTP requests the exact same way
19:49  * djazz writes his own webservers
19:49 < vro> the reason I am curious is I'm new to node but I'd like to do everything in it for a while to really learn it
19:49 < Mortchek> AAA_awright, ah, I was curious about that.
19:49 < AAA_awright> also PHP has a webserver for debugging now
19:50 < AAA_awright> built in
19:50 < vro> but i didn't know if that would be a bad idea for certain apps or not
19:50 < AAA_awright> Though I don't see a reason you couldn't use it behind a reverse proxy
19:50 < Youdaman> MelkorNemesis: and so usually it's Node + whatever db you're into... and if you use CouchDB it's almost a singularity because it can host/serve your app as well as your data
19:50 < sorella> Mortchek, yeah. NPM is what really makes me love Node. I haven't found another package manager that manages to be so sweet and â™¥ and a joy to use.
19:50 < MelkorNemesis> well I know PHP very well and sometimes it's kind of hard for me to think in node.js way
19:50 < gildean> vro: you can do everything in it, you have my blessing
19:50 < AAA_awright> sorella: Really? I do a lot of hating on the global namespace
19:50 < gildean> now go and make me some apps!
19:51 < sorella> For example, leiningen is usually a bitch â€” plus it spawns Java processes and JVM's cold start is unbearable for CLI.
19:51 < Youdaman> MelkorNemesis: it's probably the callback style of coding that's unfamiliar yeah?
19:51 < Mortchek> AAA_awright, npm could take a page from Haskell's book there
19:51 < sorella> AAA_awright, which global namespace?
19:51 < MelkorNemesis> Youdaman: yes, and I am used to write MVC applications and I dont see the MVC in node
19:51 < Mortchek> Data, Control, Text, etc. categories
19:52 < MelkorNemesis> and I am using express
19:52 < vro> well thanks gildean
19:52 < gildean> np
19:52 < AAA_awright> sorella: The single namespace that packages register under. If someone registers the 'mysql' package that's it, no one else can use 'mysql' for any other purpose, even in their own local app
19:52 < Youdaman> MelkorNemesis: have a look at Mongoose (for MongoDB for your M), maybe Mustache templates for your V, and you've already got Express for your C -- there's your MVC :) 
19:53 < AAA_awright> Portage is slightly better, it has categories
19:53 < AAA_awright> sorella: GitHub organizes things by username, then project name, that's dividing up the namespace
19:53 < sorella> AAA_awright, oh, right. You have private registers, but that doesn't quite fix the issue. I don't know Portage handles packages, haven't had the patience to try Gentoo.
19:53 < Youdaman> MelkorNemesis: or if you're familiar with another db there's likely an ORM/framework for it to give you the M part
19:54 < MelkorNemesis> Youdaman: thanks man :)
19:54 < mscdex> node.js rules!!
19:54 < MelkorNemesis> well, I mostly use mysql, but I am thinking of using some nosql like mongodb, but I am not sure if it will serve me in the same purpose yet
19:55 < MelkorNemesis> *already
19:55 < MelkorNemesis> sorry, sometimes I mix the words as I am not native en speaker
19:55 < djazz> ++mscdex;
19:55 < Youdaman> MelkorNemesis: no worries. And if you haven't already, check out a few JS books like Good Parts by Crockford or Patterns by Stefanov or Learning Node by Powers
19:56 < Youdaman> (all O'reilly books)
19:56 < djazz> ++Youdaman;
19:56 < MelkorNemesis> love Crockford, i've seen him live, cool guy, noone had no idea what he is talking about :D
19:56 < AAA_awright> *cringe* nosql is the most undescriptive term there is, call it what it is, a "document store"
19:56 < MelkorNemesis> noone had idea
19:57 < AAA_awright> MySQL can be used without any SQL, too
19:57 < MelkorNemesis> AAA_awright: oukej
19:57 < AAA_awright> Calling the query execution engine directly
19:57 < MelkorNemesis> AAA_awright: well, that's little unnecessary if we have a SQL
19:58 < Youdaman> MelkorNemesis: if you're familiar with MySQL you might find MongoDB etc a bit different to what you're used to -- instead of records in tables joined with other tables you've got documents (usually just JSON objects) so the paradigm is a bit different, but yeah there's several nice alternatives: MongoDB, CouchDB, Redis, etc. Check out: http://kkovacs.eu/cassandra-vs-mongodb-vs-couchdb-vs-redis
19:58 < AAA_awright> Eh, it has uses. SQL isn't perfectly isomorphic with the internal data model
19:59 < AAA_awright> It's exchanging one shortcoming (lots of tables) for another (lots of hand-maintained indexes)
19:59 < MelkorNemesis> the only thing that worries me is (and it's because of my lack of knowledge document databases) the "joining" like in mysql, it's probably totally different as Youdaman says
20:00 < MelkorNemesis> I mean i have user [id, name] and articles [id, user_id, text] .. and I can't imagine right now how would I display list of articles with author in mongo
20:00 < Youdaman> MelkorNemesis: you might find MongoDB easiest to transition to, as it's got some nice query functions. That said, others (like CouchDB) that use Map-Reduce might also be fun to learn -- map pretty just means "give me back a hash/object keyed by some index like date or name or whatever"
20:00 < gildean> AAA_awright: in mongo it's actually usually easier just to create more collections instead of doing too complex document-structure
20:00 < AAA_awright> Pretty much you don't do joins, you work around it with crude hacks. If I have a document store with songs, artists, and albums, you don't just use artist id numbers in the song documents, you also store the artist's name alongside
20:00 < MelkorNemesis> Youdaman: perfect
20:00 < gildean> AAA_awright: and you can put the ensureIndex inside the code somewhere
20:01 < Youdaman> MelkorNemesis: and re joins, you'd be familiar with how foreign keys work, well they have that in NoSQL databases to, some call them references or whatever, but you can have documents that point to other documents
20:01 < MelkorNemesis> AAA_awright: but when I need to change the artist's name I need to do this in every albums, right?
20:01 < MelkorNemesis> where the name appears
20:01 < AAA_awright> MelkorNemesis: The album, then every song document where it appears. It's crude.
20:02 < gildean> AAA_awright: also if you're using just one db and not sharding, then you can use the uuid of the document to do linking between collections
20:02 < gildean> but that doesn't work if the db is sharded
20:02 < MelkorNemesis> Youdaman: that's what I've wanted to hear
20:02 < Youdaman> :)
20:02 < gildean> so you'll need your own uuid-schema
20:02 < MelkorNemesis> Youdaman: btw, aren't you from czech?
20:02 < AAA_awright> garbagecollectio: MongoDB doesn't use UUIDs
20:02 < AAA_awright> er
20:02 < AAA_awright> gildean: MongoDB doesn't use UUIDs, they have their own ObjectId format
20:03 < gildean> AAA_awright: no, it uses the ObjectId, which is basically the same
20:03 < AAA_awright> which is strange
20:03 < Youdaman> MelkorNemesis: nope, Australia! unless I have an evil Czech twin?
20:03 < AAA_awright> gildean: Well not quite, it's guarenteed to order by date
20:03 < gildean> AAA_awright: but the objectid is quite cool, it has the creation timestamp in it for example
20:03 < MelkorNemesis> Youdaman: :)) cause we have the word "Jouda" .. but it probably means totally anything else
20:04 < Youdaman> MelkorNemesis: other things that might blow your mind, non-Node, are things like AngularJS or Knockout or Ember.js or Backbone -- it's more client-side than server-side JS for apps (but some can also exist server-side via Node)
20:05 < MelkorNemesis> Youdaman: I've already done one Angular.js application, but it's not public yet, so I am familiar with Angular
20:05 < MelkorNemesis> and I've been using some Backbone features
20:05 < Youdaman> MelkorNemesis: awesome
20:06 < MelkorNemesis> Youdaman: have you heard about este?
20:06 < MelkorNemesis> este.js
20:06  * Youdaman googles
20:06 < AviMarcus> MelkorNemesis, do you have any particular integration for node.js to angular?
20:06 < MelkorNemesis> Youdaman: https://github.com/Steida/este
20:06 < AviMarcus> I've made an API with node.js with restify and then built a client side gui with angular, so far
20:07 < MelkorNemesis> AviMarcus: not yet, when I did the angular.js app I hadn't been using node yet
20:07 < AviMarcus> k. Angular has some pretty cool stuff.
20:07 < AviMarcus> I haven't really used anything else
20:08 < garbagecollectio> The 250k limit is right on the fringe of what this server can pull off without violating the 1.4GB heap limitation in V8. 
20:08 < AviMarcus> using connect-roles for permissions middleware to do RBAC
20:08 < AviMarcus> (in RESTify)
20:09 < Youdaman> MelkorNemesis: looks interesting
20:09 < garbagecollectio> can someone explain the master - worker architecture
20:09 < garbagecollectio> in node clustering
20:10 < MelkorNemesis> Youdaman: the library is from our top js developer
20:10 < garbagecollectio> how this works
20:10 < MelkorNemesis> but i had no time to explore it more yet
20:11 < garbagecollectio> it seems like a weird "framework"
20:11 < Youdaman> MelkorNemesis: be interesting the see the todomvc demo he mentions on the blog
20:12 < MelkorNemesis> garbagecollectio: it's more dev stack than framework
20:12 < tweedledee> cluster is basically a wrapper around node process fork that allows cleanly sharing server FD's
20:14 < tweedledee> master forks workers, which then start whatever servers you want, and the cluster module makes sure that the underlying bindings are shared, such as socket listeners
20:17 < Youdaman> anyone else here use Mercurial as well as Git?
20:17 < garbagecollectio> how does node cluster
20:17 < garbagecollectio> know which 
20:17 < mscdex> very carefully
20:17 < mscdex> oh
20:17 < garbagecollectio> core to put itself on
20:17 < Youdaman> mscdex: not "like a boss"?
20:17 < garbagecollectio> if u have a master and worker
20:18 < tweedledee> that's handled by the os
20:18 < mscdex> that's done by the OS
20:18 < garbagecollectio> it automatically figured it out?
20:18 < tweedledee> node doesn't worry about it
20:18 < tweedledee> yes it's auto
20:18 < mscdex> the scheduler
20:18 < garbagecollectio> what if u have a master, worker, worker
20:18 < garbagecollectio> and only two cores
20:18 < tweedledee> doesn't matter, that's the operating system's job
20:18 < garbagecollectio> and what is the point of this architecture, i mean what would a master typically do and a worker do instead
20:18 < tweedledee> you should read up on OS multitasking
20:19 < tweedledee> the point is so that you can get parallelism on your server
20:19 < tweedledee> the workers work in parallel
20:19 < garbagecollectio> but is the code in the worker the same as what is in the master?
20:20 < mscdex> no
20:20 < tweedledee> they run the same .js file, but the worker branches and does something different
20:21 < garbagecollectio> but one does not program a worker or do they
20:21 < tweedledee> yes they do
20:21 < tweedledee> the worker is just the same .js file, run in worker state
20:21 < mscdex> garbagecollectio: you do, unless your machine has become self-aware
20:22 < smith_> garbagecollectio: read and learn -- http://nodejs.org/api/cluster.html
20:22 < garbagecollectio> i am so what is something a worker would do vs a master
20:22 < smith_> a master launches the workers
20:22 < tweedledee> that question doesn't really make much sense
20:22 < smith_> the workers handle your web requests or what have you
20:22 < smith_> the master distributes incoming requests to the workers
20:23 < garbagecollectio> so the workers generally have the same code among the
20:23 < garbagecollectio> them
20:23 < garbagecollectio> a
20:23 < smith_> yeah
20:23 < smith_> but now you have multi-thread support
20:23 < smith_> ta-da
20:23 < garbagecollectio> nd the master generally, u code some algorithm 
20:23 < garbagecollectio> to determine where it goes
20:23 < garbagecollectio> or set concurrency level or something
20:24 < smith_> node itself handles that for you
20:24 < smith_> yeah, set number of workers and fork
20:24 < smith_> again --> http://nodejs.org/api/cluster.html <-- example of the actual code
20:25 < smith_> also note the stability level: "Stability: 1 - Experimental"
20:25 < smith_> still an in-development feature
20:25 < tweedledee> garbagecollectio: node cluster fork is conceptually just like unix process/thread fork, it's the way all parallelism is done in unix. you should read about that first, then read the cluster module documentation
20:26 < garbagecollectio> how can node seriously get to 250k concurrent connections
20:26 < garbagecollectio> like why
20:26 < smith_> the event look and async i/o
20:26 < garbagecollectio> event loop?
20:26 < smith_> loop, even
20:26 < garbagecollectio> what is the event loop, is that a node invention or something else?
20:26 < garbagecollectio> i mean i know what it is
20:27 < garbagecollectio> but did node invent that
20:27 < jrajav> No
20:27 < smith_> not a new concept, no
20:27 < tweedledee> it's the io pattern node uses, and node didn't invent it
20:27 < smith_> but node applies it well to webv
20:27 <@mbalho> garbagecollectio: http://en.wikipedia.org/wiki/Event-driven_programming
20:27 < smith_> web*
20:27 < jrajav> It uses libuv
20:27 < jrajav> *ev?
20:27 < garbagecollectio> i dont get why using the event loop transfers bottlenecks from CPU to 
20:27 < smith_> you're basically handling an event and returning as fast as possible
20:27 < garbagecollectio> code?
20:27 < smith_> dispatching your i/o requests to be handled asynchronously
20:27 < smith_> and going on to the next event
20:27 < jrajav> libuv AND libev :P
20:28 < smith_> so the i/o doesn't block the main thread
20:28 < garbagecollectio> right
20:28 < smith_> and you get a callback when it's done
20:28 < tweedledee> event loop doesn't transfer bottlenecks, really. all it does is make sure your code is always running as opposed to waitng for some IO to complete
20:28 < jrajav> ^
20:28 < smith_> yes, that
20:28 < garbagecollectio> but the main thread blocks the callbacks
20:28 < jrajav> Uh, no?
20:28 < smith_> what?
20:28 < smith_> no, when a callback completes, it's pushed onto the event queue
20:28 < garbagecollectio> ur functions in the main thread need to complete before any callback is executed
20:28 < jrajav> Callbacks are functions that are waiting to be called. It's how Node.js handles the concurrency problem (as opposed to threads)
20:29 < garbagecollectio> i know
20:29 < smith_> yeah, righjt
20:29 < smith_> right*
20:29 < smith_> which is why you get through your code as fast as possible
20:29 < smith_> so you can keep the loop spinning
20:29 < jrajav> Exactly
20:29 < smith_> the slow stuff, i/o, is handled asynchronously
20:29 < jrajav> And that's why you see so many asynchronous patterns
20:29 < Youdaman> I'm guessing if I'm using Mercurial then I can specify "repository" : { "type" : "hg", "url" : "http://bitbucket..." } in my package.json -- i.e. the type is "hg" not "mercurial" because it has to correspond to a system command yeah?
20:29 < garbagecollectio> and thus no threads, thus no cpu/ram consumption
20:29 < jrajav> So that code can "hand off" to the next tick often
20:29 < JohnMcLear> so people actually like using jade?
20:30 < Youdaman> JohnMcLear: i don't mind it
20:30 < smith_> i like handlebars.js (hbs for express)
20:30 < smith_> more portability
20:31 < jrajav> Youdaman: No, it should be mercurial
20:32 < jrajav> Actually, I'm not sure that it matters
20:32 < sorella> Does NPM even do anything with the "repository" meta data?
20:32 < Youdaman> jrajav: thanks, I haven't tried yet, but no doubt will, as I prefer Mercurial to Git (please don't hit me)
20:32 < AviMarcus> wow, you guys are really polite.
20:32 < smith_> well there's the package info page/command
20:32 < Youdaman> (i use both)
20:33 < smith_> AviMarcus: good to hear?
20:33 < AviMarcus> smith_, I suppose. I lost much of my patience explaining basics.
20:33 < jrajav> Youdaman: Lots of people do. They're both just tools, and they both work great
20:33 < smith_> AviMarcus: ah, i see
20:33 < Youdaman> AviMarcus: you were expecting stereotypical programmer rudeness perhaps? :)
20:34 < sorella> Youdaman, I do prefer Mercurial over Git as well for the API. I use hg-git to leave my Mercurial projects on Github so Git people can contribute easily too.
20:34 < AviMarcus> Youdaman, I hear about that a lot, but actually not in nearly any of the channels I frequent. However, I was expecting "please read some basic newbie guides and then we can talk".
20:34 < Youdaman> jrajav: yeah that's good to hear lots of people do. I started with git, moved to hg, and pretty much use it for all my dev, but obviously have to use git when using github etc
20:34 < Youdaman> sorella: nice! thanks
20:35 < tweedledee> I kinda wish hg won the war, but github kind of sets the standard now
20:35 < Youdaman> AviMarcus: you'll always come across those types -- they don't realise it's easier not to type anything if they're really that annoyed
20:35 < sorella> tweedledee, huh, but Github isn't a DVCS D:
20:36 < tweedledee> I know, but because of GH, git is the standard
20:36 < smith_> but github sets the standard for repository hosting
20:36 < sorella> And you can use Mercurial on Github through the hg-git extension (that's what I do)
20:36 < Youdaman> tweedledee: you can always use hg for your projects -- bitbucket has had a facelift recently and is looking sexier... and the free private projects is a winner with me vs github payed plans
20:36 < jrajav> sorella: Yeah, but it's an easy way to put the D in DVCS
20:36 < tweedledee> yep I use BB
20:36 < smith_> bitbucket has been getting a lot better recently
20:37 < smith_> though lots of stuff is on github already
20:37 < sorella> Yeah, newest bitbucket designs do look cool.
20:37 < jrajav> I think bitbucket has had its cool license permanently revoked for most people :P
20:37 < Youdaman> sorella: oh, so this plugin lets me actually just use hg as normal on a git URL?
20:37 < Youdaman> zomg! http://hg-git.github.com/
20:37 < sorella> Youdaman, yeah. You can interface with any git repository using mercurial.
20:37  * Youdaman hugs sorella
20:38 < smith_> Youdaman: a better life for you!
20:38 < sorella> Youdaman, I think there's a similar thing for git that lets Git-people interface with Mercurial repositories
20:38 < ThiefMaster> sorella, why would someone want to do that in this direction? :P
20:38 < tweedledee> unfortunately hg-git kind of dies for huge repositories
20:38 < ThiefMaster> (git > hg)
20:38 < smith_> i would be happy if you could point me to that
20:38 < tweedledee> I have 20K commits (lots of binary) and using hg-git takes forever to do anything
20:38 < sorella> tweedledee, true, the conversion might be quite slow if you have tons of stuff.
20:40 < sorella> ThiefMaster, it might be, feature-wise or community-wise. I don't think it is API-wise, though. I've had a better time getting myself around Mercurial commands than remembering Git flags.
20:40 < tweedledee> yeah hg is kind of the mac of DVCS, it just works and it doesn't break for no reason (most of the time)
20:41 < sorella> It also comes intentionally with less features out of the box :3
20:41 < sorella> The only analogy we can't draw is price :3
20:47 < mcw> \help
20:59 < garbagecollectio> in node
20:59 < garbagecollectio> what if two requests hit node at the same time
20:59 < smith_> they are queued
20:59 < smith_> and executed
21:00 < smith_> and responded to
21:00 < garbagecollectio> but supposedly node goes so fast that
21:00 < garbagecollectio> u can do 250k connections
21:00 < garbagecollectio> i mean at what point does it stay to slow down
21:00 < smith_> why don't you run a benchmark? it depends on your code
21:00 < smith_> 250k is just a number
21:00 < tweedledee> and it depends on your hardware
21:00 < tweedledee> and all sorts of factors
21:01 < garbagecollectio> hardware not really
21:01 < garbagecollectio> when it comes to node
21:01 < tweedledee> there's a lot of hardware it depends on
21:01 < garbagecollectio> i mean to some extent
21:01 < garbagecollectio> i mean ram and cpu
21:01 < tweedledee> for example, not all routers can handle that kind of traffic
21:03 < tweedledee> I don't know where that 250k comes from, but it's a pretty pointless metric. if you're concerned about scaling to 250K connections, node makes runnign a test trivial
21:03 < AAA_awright> tweedledee: Git is superior in pretty much any objective standard to Mercurial, why?
21:04 < garbagecollectio> http://blog.caustik.com/2012/04/10/node-js-w250k-concurrent-connections/
21:04 < AAA_awright> Mercurial has no solid notion of tags or branches, which is a problem
21:04 < AAA_awright> If you want to use, oh I don't know, tags or branches
21:04 < garbagecollectio> 250k basically reaches the 1.4 gig V8 limit
21:04 < tweedledee> actually, git has no concept of branches
21:04 < tweedledee> git is just a bunch of objects
21:04 < tweedledee> mercurial has first-class branches
21:04 < tweedledee> also there's no such thing as an objective standard in DVCS
21:04 < clever> garbagecollectio: does that include 64bit machines?
21:05 < tweedledee> if I recall V8 used to have huge heap problems, but not anymore
21:05 < AAA_awright> tweedledee: Git relies on branches, a branch is literally a 41-byte file containing a commit id and a newline
21:05 < tweedledee> that's long been fixed for 64-bit
21:05 < AAA_awright> Mercurial has no such thing
21:05 < clever> garbagecollectio: i would expect bigger problems just with the open fd limit, i thought that was only 2 bytes?
21:06 < garbagecollectio> it hasn
21:06 < garbagecollectio> t
21:06 < smith_> >   hg branch
21:06 < garbagecollectio> longed been fixed
21:06 < tweedledee> AA_awright: then that's not a branch, that's just a different name for a hash
21:06 < garbagecollectio> its not fixed
21:06 < tweedledee> git doesn't track branches, it tracks hashes/commits
21:06 < garbagecollectio> when was it fixed?
21:06 < sorella> AAA_awright, mercurial has SVN-like branches as meta-data, and now Git-like branches which are called Bookmarks.
21:07 < AAA_awright> tweedledee: What do you mean by track? It has a single standard for pointing at commits and saying "this commit is that thing"
21:07 < sorella> AAA_awright, in fact, it's because of bookmarks that lossless Mercurialâ†’Git conversion is possible.
21:07 < AAA_awright> And tags?
21:08 < sorella> AAA_awright, tags are metadata that give a commit (by hash) a friendly name.
21:08 < AAA_awright> sorella: It's really an admission "oops, we messed up branches"
21:08 < sorella> AAA_awright, not really, I hardly use bookmarks, but I use branches a lot.
21:08 < AAA_awright> SVN-like branches is pretty much the worst thing you can say about a revision control system
21:08 < sorella> AAA_awright, it depends on how your workflow is set up.
21:08 < AAA_awright> SVN has no such thing as branches :p
21:08 < AAA_awright> At least CVS has branches
21:09 < tweedledee> it's really simple: git branches don't really exist, they're just a name for a commit. mercurial actually has a notion of "this commit belongs to this branch", unlike git, where it's much more of a de-facto thing
21:09 < AAA_awright> CVS stores more useful information than SVN does
21:09 < sorella> AAA_awright, SVN has no concept of branches, it uses folders, yes. Mercurial has a concept of branches, which are lines of development.
21:09 < AAA_awright> tweedledee: Yes, they really exist, they take up 41 bytes on your filesystem
21:10 < sorella> AAA_awright, in Mercurial, a branch is how a subtree of your commit history is called.
21:10 < ThiefMaster> CVS is a piece of shit
21:10 < ThiefMaster> having a non-dot-prefixed folder in every goddamn folder of the source tree is super annoying
21:10 < AAA_awright> What sort of argument is that? "Aliases don't really exist, it's just a pointer to another thing"
21:10 < smith_> ThiefMaster: thank you for this revolutionary revelation
21:10 < garbagecollectio> is the V8 heap limit
21:10 < AAA_awright> ThiefMaster: SVN does the same thing...
21:10 < ThiefMaster> svn uses .svn
21:10 < sorella> AAA_awright, but once you open a branch, you can only open a new branch over that subtree, or close that branch, or merge it back on another branch.
21:10 < tweedledee> well we can argue terminology, but in git a branch is a pointer structure, in mercurial a branch is real metadata that's immutable and part of history
21:10 < garbagecollectio> just you can't  have more than 1.4gig of objects
21:10 < ThiefMaster> at least a *bit* better
21:11 < tweedledee> I'm not arguing that one is better than the other
21:11 < smith_> garbagecollectio: https://encrypted.google.com/search?hl=en&q=v8%20heap%20limit
21:11 < Youdaman> I like how I asked a question re using Mercurial in package.json only to return to the channel to see an ongoing discussion about the various version control programs :D
21:12 < AAA_awright> sorella: A branch which really isn't a branch, for the purposes of revision control, just a commit label (I'd say tag but that's well-defined too)
21:13 < sorella> AAA_awright, that's what tags are for in Mercurial.
21:13 < garbagecollectio> smith_ not explained anywere
21:14 < sorella> AAA_awright, branch: a definite name for a subtree in the commit history, that can never be changed/tampered with; tags: an alias to a commit; bookmarks: Git-branches.
21:14 < sorella> AAA_awright, so, Mercurial actually has more features in that case, but whether that makes more sense or not is up to who is using the version control system.
21:14 < AAA_awright> I'm talking about branches in the definite, well-defined revision control study, not Mercurial's botched usage
21:14 < ExxKA> Hey guys. I have been trying to debug a mocha unit test I wrote with the --debug argument and a "debugger;" statement, but it does not break, it just hangs. Do you have any ideas?
21:15 < AAA_awright> (like how SVN also botches)
21:15 < tweedledee> what's the well-defined revision control study that you refer to?
21:15 < sorella> AAA_awright, there's an agreed upon notion of branches? Would you care to link me to an white-paper or thesis on the subject?
21:15 < tweedledee> sorella: my thoughts exactly
21:15 < garbagecollectio> so if you have to go beyond having about 250k connections, 1.4gb of heap space taken up, how do you go beyond that?
21:15 < mscdex> over 9000 branches!
21:15 < garbagecollectio> you add more cores?
21:16 < AAA_awright> sorella: Back when the Kernel used BitKeeper, you bet. Hence when people like Linus rolled his own, he ended up getting it correct
21:16 < smith_> garbagecollectio: as has been mentioned before, the 1.4gb limit has been fixed long ago
21:16 < garbagecollectio> does V8 heap only apply to one  core
21:16 < garbagecollectio> does each core have its onw heap
21:16 < garbagecollectio> smith_ no it hasn't
21:16 < garbagecollectio> it's a "soft" limit
21:16 < garbagecollectio> they still kill connections
21:16 < garbagecollectio> it used to be a "hard" limit
21:16 < smith_> garbagecollectio: also, 250K connections using 1.4GB is only applicable to one specific application, not all of them,
21:16 < garbagecollectio> but now they still delete stuff when it starts approaching 1.4 gb
21:17 < garbagecollectio> smith_ true, im just using a hypothetical
21:17 < AAA_awright> Branches exist to facilitate commit-object operations within a certain development context
21:17 < sorella> AAA_awright, "correct" is a difficult definition here. Also, do you have a post-mortem or any other kind of report on that?
21:17 < sorella> AAA_awright, see Object Orientation. Or Functional Programming. These are pretty familiar concepts, yet very their meaning is still quite fuzzy. As in, there's no definitive, agreed-upon concept of either.
21:18 < AAA_awright> When you start embedding that information into your commits you're mixing your semantics up
21:18 < sorella> Or perhaps I should just say it's ever-changing.
21:18 < harrydog> if i want to use redis for the memory store, do i say "npm install redis" in the terminal or "npm install connect-redis" ?
21:18 < AAA_awright> Object Oriented is well-defined, you have to support inheritance, polymorphisim, etc
21:18 < sorella> harrydog, depends on which library you want to use to interface with the Redis database.
21:18 < smith_> garbagecollectio: https://code.google.com/p/v8/issues/detail?id=847
21:18 < harrydog> is connect-redis simpler?
21:18 < smith_> CTRL+F "fix"
21:19 < AAA_awright> Functional programming I don't call myself any expert in, but it's completely unambigious whatever the definition is
21:19 < smith_> note that this is from 2011
21:19 < sorella> AAA_awright, it's not ~that~ well defined, actually. If you ask people around, even people who're researching Object Orientation, you're going to receive lots of different answers.
21:19 < garbagecollectio> Comment 21 by project member erik.corry, Sep 19, 2011
21:19 < garbagecollectio> The default limit is still 700Mbytes on 32 bit and 1400Mbytes on 64 bit.  You can up the limit with --max-old-space-size=2000  The unit is Megabytes.  On 32 bit systems you probably can't set it much higher due to the lack of virtual address space.  The limit is not known on 64 bit.
21:19 < garbagecollectio> you are, unfortunately, wrong
21:19 < smith_> The limit is not known on 64 bit.
21:19 < sorella> For example, if you ask Alan Kay what Object Orientation is, you'll receive a very different answer than if you had asked Willian Cook. Both are OO researchers.
21:19 < AAA_awright> sorella: I can definitely say ECMAScript is not object-oriented (for the better)
21:19 < smith_> I can quote things too.
21:19 < tweedledee> this git/merc argument is so pointless, there's no "correct" definition of a "branch", "object-oriented", and "botching" (or else please enlighten me with links)
21:20 < smith_> You can up the limit with --max-old-space-size=2000
21:20 < garbagecollectio> smith_ u have to do a workaround urself, the workaround is not included 
21:20 < garbagecollectio> lol
21:20 < garbagecollectio> wow 1.4 to 2
21:20 < harrydog> object orientation just means organizing functions and variables into objects, functional just means writting functions
21:20 < garbagecollectio> so its a 2gb limit
21:20 < garbagecollectio> this does not answer my questino
21:20 < smith_> > The limit is not known on 64 bit.
21:20 < garbagecollectio> how do i go beyond that, do i need to use multiple cores?
21:20 < sorella> AAA_awright, ECMAScript fits William Cook's defintion of Object Orientation, iirc.
21:20 < smith_> > The limit is not known on 64 bit.
21:20 < AAA_awright> harrydog: No, that's not what functional is, at all
21:20 < smith_> > The limit is not known on 64 bit.
21:20 < smith_> garbagecollectio: 2GB is an example.
21:20 < garbagecollectio> smith_ where does it say that?
21:20 < smith_> garbagecollectio: read the quote you are posting
21:21 < garbagecollectio> well according to caustik(a blog) the limit is basically still 1400
21:21 < garbagecollectio> even though u can up it
21:21 < garbagecollectio> heres the pont though
21:21 < garbagecollectio> how can u go beyond tht
21:21 < AAA_awright> sorella: It's not enough just to have object->method(argument) be an alias for method_thefunction(object, argument)
21:21 < sorella> AAA_awright, functional programming has a pretty fuzzy meaning as well, if you ask researchers on the area. Specially if you ask researchers working in different languages. Like Haskell vs Scala vs Clojure vs Racket.
21:21 < AAA_awright> C++ has a lovely support library to be able to support multiple inheritance
21:22 < AAA_awright> (not an OO requirement, but for example)
21:22 < sorella> AAA_awright, JS can also support multiple inheritance. It's just not baked right in. At any rate, multiple inheritance is not a requirement for OO.
21:22 < misterhat> lol
21:22 < misterhat> JS can support a lot of things
21:22 < tweedledee> AAA_awright, if you ask the guy who invented smalltalk --- the guy who invented the term "OO"... he will tell you C++ isn't OO at all
21:22 < misterhat> :P
21:22 < sorella> In any definition I know, at least.
21:22 < misterhat> there's like classical OO
21:22 < garbagecollectio> how can u go beyond a filled up heap?
21:22 < misterhat> and OO
21:22 < garbagecollectio> a V8 limitation?
21:22 < AAA_awright> ES can't support multiple inheritance in any meaningful way, you can get equivalent results though
21:23 < smith_> garbagecollectio: well, first you could read the post you're referencing
21:23 < sorella> AAA_awright, at any rate, discussing language won't get us very far. As isn't discussing what the right meaning for "branches" ought to be.
21:23 < smith_> garbagecollectio: The limit is not known on 64 bit.
21:23 < harrydog> is connect-redis to redis kind of like what mongoose is to mongo
21:23 < smith_> Wrong clipboard.
21:23 < smith_> garbagecollectio: http://blog.caustik.com/2012/04/11/escape-the-1-4gb-v8-heap-limit-in-node-js/
21:23 < sorella> AAA_awright, Proxies.
21:23 < smith_> There we go.
21:23 < garbagecollectio> smith_ but say u dont want to do that
21:23 < garbagecollectio> how else to scale it
21:23 < garbagecollectio> is it one heap per core or one heap per OS
21:23 < smith_> garbagecollectio: spin up multiple processes, perhaps
21:23 < smith_> garbagecollectio: heap is per process
21:23 < smith_> garbagecollectio: is that what you were trying to ask?
21:24 < garbagecollectio> yeah
21:24 < garbagecollectio> per process
21:24 < smith_> garbagecollectio: m'kay
21:24 < garbagecollectio> so if u have tow node processes
21:24 < AAA_awright> sorella: Not in ECMAScript 5 at least, nor do I think there's any useful application for proxies (even when you think you really do need it)
21:24 < garbagecollectio> two
21:24 < sorella> AAA_awright, https://gist.github.com/1390046
21:24 < garbagecollectio> u have two v8s? and two heaps?
21:24 < smith_> yep
21:24 < sorella> That's ES5, with multiple inheritance.
21:24 < garbagecollectio> smith_ that's not true though because the caustik guy ran into trouble
21:24 < sorella> AAA_awright, and multiple inheritance in the sense of Self or Slate, which are "pretty close" to Smalltalk.
21:25 < misterhat> i've been loving using mixins
21:25 < garbagecollectio> smith_: he ran into trouble with using multiple cores
21:25 < AAA_awright> sorella: You have to manually specify all the methods that you want to ever use, that's no good
21:26 < AAA_awright> And in any event ES has superior support for any reason you could want to use that on
21:26 < sorella> Mixins are another approach to multiple inheritance (There's an implementation in JavaScript). Traits are yet another (There's an implementation in JavaScript). Multiple delegation is another (There's an implementation in JavaScript). Classical Python-based multiple inheritance is possible (There's an implementation in JavaScript).
21:26 < smith_> garbagecollectio: you could, perhaps, not use the node.js cluster system
21:26 < smith_> garbagecollectio: put a different load balancer in front of it
21:27 < misterhat> mixins are a better way to do it tbh
21:27 < garbagecollectio> smith_: are u just kinda bullshitting?
21:27 < smith_> garbagecollectio: and have it split the workload between your node processes
21:27 < smith_> garbagecollectio: no?
21:27 < garbagecollectio> smith_: how do u do multiple node processes
21:27 < misterhat> JS is just such a dynamic language
21:27 < garbagecollectio> smith_: without using cluster
21:27 < misterhat> in terms of what paradigms you can use
21:27 < smith_> garbagecollectio: you run node multiple times
21:27 < smith_> garbagecollectio: open up your terminal
21:27 < garbagecollectio> oh
21:27 < smith_> garbagecollectio: open two tabs
21:27 < garbagecollectio> smith_: ur saying just run node on different ports
21:27 < smith_> garbagecollectio: sure, multiple processes, listening on multiple ports
21:27 < misterhat> yeah
21:28 < smith_> garbagecollectio: then put a load balancer in from of it
21:28 < misterhat> that's how it scales 
21:28 < misterhat> :P
21:28 < smith_> ront*
21:28 < smith_> front*
21:28 < misterhat> which is great
21:28 < smith_> garbagecollectio: have it point at your individual node process ports
21:28 < garbagecollectio> smith_: is the node cluster system multiple processes or one process? or multiple processes with shared IPC memory
21:28 < smith_> garbagecollectio: i believe multiple processes, but i haven't used it myself
21:29 < tweedledee> it's multiple processes that communicate over stdio
21:29 < smith_> garbagecollectio: yeah, multi-process
21:29 < garbagecollectio> smith_: so your saying the V8 limit would be whatever the v8 limit is x 3 if I had 3 worker processes?
21:29 < smith_> "To take advantage of multi-core systems the user will sometimes want to launch a cluster of Node processes to handle the load."
21:29 < smith_> from the docs
21:29 < smith_> garbagecollectio: yep!
21:29 < tweedledee> there is nothing special about node cluster, it's really just unix process pipe() and fork()
21:29 < smith_> the caustik guy ran into trouble b/c the master process was exceeding the limit passing data to the workers
21:29 < garbagecollectio> oh
21:30 < smith_> so if you somehow run into that yourself, just use a non-node load balancer
21:30 < garbagecollectio> to send it direct to the workers
21:30 < smith_> and not the cluster system
21:30 < garbagecollectio> ?
21:30 < smith_> yeah
21:30 < smith_> then each worker -- a node process -- has its own "v8" and heap
21:30 < garbagecollectio> and scale up the ram
21:30 < smith_> exactly
21:30 < Youdaman> sorella: i had to install Python, then VC++, then tweak a core Python lib so it knew about the right version of VC++, then git clone dulwich (git Python lib), then manually configure the path to the hggit lib in .hgrc... and then... bam, I can now "hg clone <some git repo>" :D
21:30 < smith_> and cpu as necessary
21:30 < sosnon> i am trying to install tidy with npm, but it fails; this is the log: http://pastie.org/5468196 looks like tidy is broken ('build failed: ...') and it is not my fault; can someone confirm that?
21:30 < AviMarcus> garbagecollectio, what are you doing that needs so much ram?
21:30 < smith_> and b/c of the event loop system, multiple workers shouldn't put so much strain on the cpu
21:31 < smith_> though, in most instances, you won't even need that much RAM
21:31 < AviMarcus> ... unless you're explicitly CPU-intenstive stuff. Like image manipulation, fibbonachi, or reg-ex'ing gigabytes of data.
21:31 < smith_> to go over the limit, whatever it is at this point
21:32 < smith_> AviMarcus: in which case you could use C++ extensions, outside the v8 heap size (i believe?)
21:32 < garbagecollectio> AviMarcus: packet inspection
21:33 < tweedledee> garbagecollectio: some practical advice for you: it doesn't look like you fully understand node or unix. also, it's extremely unlikely you'll hit *any* of these limits in the real world. I recommend you just go try out some things and run some tests. your questions are pretty much the definition of premature optimization.
21:33 < AviMarcus> garbagecollectio, of how much data?
21:33 < garbagecollectio> tweedledee: appreciate your comments, but they are unfortunately misguided
21:33 < AviMarcus> lol that's kinda what he said to you.
21:33 < tweedledee> then guide me
21:33 < garbagecollectio> AviMarcus: 50 terrabytes/day
21:34 < tweedledee> what are you trying to accomplish?
21:34 < garbagecollectio> building something
21:34 < garbagecollectio> anyway
21:34 < AviMarcus> 600 megabytes/second on average?
21:35 < garbagecollectio> yeah
21:35 < AviMarcus> that's... that could be a lot.
21:35 < AviMarcus> my last script (last week) had CPU on regex as the bottleneck. If it mattered, that would have been the thing to split up into workers
21:35 < garbagecollectio> javascript regex is better than most
21:36 < garbagecollectio> you  mean just split up the regex operation to workers?
21:36 < AviMarcus> one worker per core and a master that splits up the packets and sends them to workers
21:36 < smith_> garbagecollectio: node.js is better for i/o bound tasks than cpu-bound ones
21:36 < garbagecollectio> right but we are hitting the node cluster data liit
21:36 < AviMarcus> yeah, ryan created node.js primarily for doing operations that are counted in milliseconds
21:36 < tweedledee> garbagecollectio: indeed, if you want to do realtime packet proxy inspection... node.js probably isn't a good choice
21:37 < garbagecollectio> AviMarcus: you just exported a single operation to workers?
21:37 < AviMarcus> garbagecollectio, you can.
21:38 < AviMarcus> garbagecollectio, e.g. fork a child then send it messages with ipc: http://nodejs.org/api/child_process.html#child_process_child_send_message_sendhandle
21:38 < AviMarcus> so you can fork several and send them in round-robin to the pool of workers
21:39 < AviMarcus> make 1 worker per core and then you can max out the machine
21:39 < AviMarcus> why are you hitting a ram limit?
21:39 < AviMarcus> it sounds like you need to be processing in real time
21:39 < garbagecollectio> right
21:39 < AviMarcus> OR post-processing off disk. But 600mb/second is kinda fast to right to disk..
21:39 < AviMarcus> write*
21:40 < garbagecollectio> but not to redis
21:40 < euoia> Hello everybody. I have a fresh couchdb install in Admin party mode, I can delete databases using cURL, but when I attempt to delete a database using nano I get an error method_not_allowed. Anyone have any ideas?
21:40 < garbagecollectio> hiredis
21:40 < AviMarcus> true, but you need the ram for that
21:40 < garbagecollectio> 40,000 operations/second
21:40 < AviMarcus> euoia, are you sure you're in the right channel?
21:41 < garbagecollectio> what is the child process od?
21:41 < euoia> AviMarcus: I think so, I'm using the nano module in npm
21:41 < AviMarcus> Ah
21:41 < garbagecollectio> AviMarcus: what is the child process thing vs the worker thing
21:41 < AviMarcus> garbagecollectio, if you want real time, skip redis and go straight to the node.js scripts, I *think*.
21:41 < AviMarcus> garbagecollectio, it's a child of whatever your master script that launched it is.
21:41 < garbagecollectio> what does that mean a child?
21:41 < AviMarcus> child process is a way to create workers
21:42 < AviMarcus> one process that has multiple threads
21:42 < AviMarcus> a fork/childprocess is one of those threads
21:42 < AviMarcus> but you have to explicitly tell it what to do then
21:43 < AviMarcus> That's about all my ideas. I got stuff to do. Good luck.
21:44 < padreSpiletto> hey, i'm ready to learn Node.js (on Fedora 15)
21:45 < padreSpiletto> what's the best and 'clean' way to install node in Fedora 15
21:45 < padreSpiletto> ?
21:46 < AviMarcus> padreSpiletto, probably this - all packages will lag stable: http://nodejs.org/download/
21:46 < AviMarcus> erm sec.
21:46 < AviMarcus> where was the install instructions?
21:47 < AviMarcus> ah, https://github.com/joyent/node/wiki/Installing-Node.js-via-package-manager
21:47 < AviMarcus> debian instructions seem to be standard *nix compile
21:47 < padreSpiletto> AviMarcus: thanks, what are the requirements?
21:47 < padreSpiletto> ok
21:48 < AviMarcus> just make, python, and g++
21:48 < padreSpiletto> great
21:51 < garbagecollectio> isnt
21:51 < garbagecollectio> isnt child process same as multi threading
21:51 < garbagecollectio> for node
21:52 < garbagecollectio> the child stuff
21:53 < garbagecollectio> ??
21:54 < AviMarcus> garbagecollectio, yes.. which.. is what you wanted, it sounds like.
21:54 < jrajav> A process is not the same thing as a thread
21:55 < garbagecollectio> so who is right
21:55 < garbagecollectio> node's child library
21:55 < smith_> process != thread
21:55 < garbagecollectio> it creates processes or threads
21:55 < garbagecollectio> is that multi threading?
21:55 < smith_> processes
21:55 < smith_> node.js's child_process library
21:55 < garbagecollectio> right
21:55 < _numbers> isnt this simpler than using async.js? http://codepen.io/joe/pen/Btmlv
21:56 < smith_> not multi-threading, full processes
21:56 < garbagecollectio> right
21:56 < garbagecollectio> so hoe can i make threads
21:56 < garbagecollectio> not processes
21:57 < smith_> node.js doesn't have built-in support for that
21:57 < smith_> but you can use the fibers third-party module
21:57 < smith_> if you *must*
21:57 < smith_> but threads aren't really a concept that meshes w/ node
21:57 < garbagecollectio> and what is the difference between child process and the cluster library in node
21:57 < niggler> isaacs how difficult would it be to have .load autocomplete with filenames?
22:00 < garbagecollectio> and what is the difference between child process and the cluster library in node
22:01 < jrajav> _numbers: That's honestly pretty awesome
22:01 < jrajav> _numbers: I may actually use that
22:02 < _numbers> jrajav: thx :) now i am wondering what if something like this coffeescript http://codepen.io/joe/pen/konIp compiled to that js
22:03 < jrajav> Hmm, that syntax seems a little clunky
22:03 < jrajav> It seems like it would be better to accept a series of functions rather than repeat the keyword over and over
22:04 < _numbers> it would be cool if you could mix them like  series...series...parallel...parallel...finally  where all have to complete before the finally is executed
22:05 < smith_> _numbers: you mean this? https://github.com/caolan/async
22:05 < smith_> i use it all the time.
22:05 < smith_> really useful
22:05 < _numbers> i know i just think process flow should be part of the language with minimal syntax
22:06 < euoia> My previous problem was caused by passing undefined as the database name - the error message was a just a bit unhelpful
22:06 < smith_> oh, i see. thought you were talking about the module
22:06 < smith_> the codepen link gave me a compile error
22:07 < _numbers> the second one is proposed coffeescript syntax that isnt supported yet. the first one is pure js that compiles
22:08 < smith_> ah, gotcha
22:08 < jrajav> Personally I shy away from using async
22:08 < smith_> icedcoffeescript, or something else?
22:09 < jrajav> It's not for any sound, obective reason - I just prefer such basic things as flow control to be immediately apparent, not depend on knowing a library's syntax
22:09 < jrajav> That's why this solution appeals to me :O
22:09 < _numbers> i'll keep experimenting. rather than explicitly defining series, parallel, waterfall, etc. it might be cleaner to go with the tamejs/iced-coffee-script 'await' and 'defer' approach
22:10 < jrajav> This solves one of the biggest problems with callbacks - the flow control doesn't follow the top-to-bottom flow of the code itself if you manage your callbacks by defining them earlier
22:10 < _numbers> i just hate that iced coffeescript compiles to absolute unreadable shit when its finally in js
22:10 < _numbers> jrajav: ya exactly
22:10 < TehShrike> I'm with jrajav, I've become comfortable with straight JS syntax for async stuff, and I feel confident in writing it out in a fairly clear manner
22:11 < jrajav> _numbers: Are you going to pound this out on the pure js side too or mainly the coffeescript proposal? Because I may actually run with this and make something
22:11 < jrajav> Like an article on it
22:11 < smith_> pure js syntax is frustrating for loops and conditionals, though
22:11 < AviMarcus> _numbers, can you explain what series.shift()() does? I don't get it :P
22:11 < TehShrike> jrajav: Expounding a bit on callbackhell.com, perhaps?
22:12 < jrajav> I was actually thinking of that :)
22:12 < jrajav> AviMarcus: shift is an array method
22:12 < AviMarcus> yeah, remove first
22:12 < jrajav> AviMarcus: It's like "pop" on the beginning of the array
22:12 < AviMarcus> but how does it execute?
22:12 < jrajav> AviMarcus: The second set of () then invokes the function
22:12 < jrajav> That was at index 0
22:12 < AviMarcus> oh. pop get it. then (). cool.
22:12 < _numbers> jrajav: ur welcome to run with it. i will experiment with a similar pure-js readable pattern for 'await' and 'defer' now. i'd rather not have to fork/modify coffeescript; my hope is if i can get it looking clean in js, then it will look even better in coffee
22:13 < AviMarcus> _numbers, I understand series now. Fascinating.
22:13  * AviMarcus is kinda new to callback hell, most of my stuff is _relatively_ simple so far
22:14 < jrajav> Oh, you'll find it :)
22:14 < jrajav> Get comfortable with defining functions as variables rather than inline. That's one of the best things you can do to mitigate it.
22:15 < AviMarcus> as variable? not just as a straight function?
22:16 < jrajav> Uh.. perhaps you're misunderstanding me. Whether you pass a function literal defining a function value to a function directly, or a variable containing one, it's the same result
22:17 < AviMarcus> right, yeah. I do that.
22:17 < AviMarcus> ah. in parallel, "next" is defined before any of them get called.
22:17 < AviMarcus> what scope is next in?
22:18 < jrajav> Hmm. as written, the global scope. Minor bug
22:19 < AviMarcus> I still don't quite understand how next gets defined and used. If it's parallel.next then how is it called within the functions?
22:20 < jrajav> It's not parallel.next. It's an element of the array
22:20 < jrajav> And it's *also* assigned to the variable next
22:20 < AviMarcus> oh array, not object. Doh.
22:20 < jrajav> The assignment operator returns the value that was assigned
22:20 < _numbers> hm i'll lint it so that is more clear
22:21 < garthk> Morning, all. 
22:21 < _numbers> although personally i'm ok with next() being in global scope
22:21 < AviMarcus> but there's a scope issue as written?
22:21 < AviMarcus> might they not conflict?
22:22 < AviMarcus> wow that could be said better.
22:22 < jrajav> _numbers: Well, what if you use this multiple times in one unit of code?
22:22 < garthk> So: I want to get all substack on my module sizes for my work stuff. That'll require a private NPM, though.
22:22 < jrajav> _numbers: Then you would overwrite the first next
22:22 < jrajav> _numbers: And it would malfunction
22:22 < garthk> Private NPM: is this article still the latest and greatest? http://node-code.com/blog/?p=155
22:22 < jrajav> substack is a freaking monster
22:22 < jrajav> He litters up my github feed :P
22:22 < _numbers> ya. if you're mindful you could change the next variable name. or ya you could get in the habit of typing a little bit more and instead of naming it there just follow the var= definition with;  parallel.next = parallel.slice(-1)[0];
22:23 < garthk> jrajav: oh, I hear you on that. :)
22:24 < garthk> Sometimes I have a problem. Then I think, â€œOh, substack will have solved this and published a module. I'll go look for it.â€ Then I have two problems. 
22:25 < _numbers> garthk: hah. thats a funny principle:  "i have a problem. when i use a library to solve it, i now have two problems."
22:25 < _numbers> that is often how it goes
22:25 < _numbers> lib maintainer promises features, delivers bugs :)
22:27 < jrajav> _numbers: It might be better to define next as a method on the array
22:28 < jrajav> Or simply define it as a variable in the same scope as parallel
22:28 < jrajav> Both are preferable to manual name mangling, IMO
22:28 < garthk> _numbers: I first picked up on it from the Python community, where Fredrik Lundh had a 1998 Jamie Zawinsky quote about regular expressions and two problems. Turns out Jamie, in turn, repurposed an old saw about people using 'sed'. It wouldn't surprise me at all if it goes back to mainframe days, or perhaps even mechanical engineering. http://regex.info/blog/2006-09-15/247
22:28 < jrajav> You could also skip using next() at all, at the price of more obscure continuation passing in the parallel functions
22:29 < jrajav> With something like parallel.slice(-1)[0], like you said
22:29 < garthk> Haha! The author of that article imagines it being used in WW1 with troops thinking, "I have a problem, I'll go ask the officersâ€¦"
22:30 < _numbers> jrajav: agreed
22:30 < _numbers> jrajav: ya thats what i had at first actually. that might be the best
22:31 < jrajav> I think var next = parallel.slice(-1)[0]; is best
22:31 < jrajav> Or define it at the top and just var next = parellel[0]
22:31 < jrajav> But it's probably better to have the "finalize" function at the bottom
22:32 < _numbers> or a global next_parallel() function could be defined, and thats always what it means
22:32 < _numbers> ah but then we're using libs
22:32 < jrajav> Erm, and how would you genericize that
22:32 < jrajav> Without having to pass in an argument
22:33 < jrajav> Or put it on the array prototype
22:33 < jrajav> (which is just a milder global scope)
22:33 <@Nexxy> and an even worse idea
22:33 < _numbers> well it would be nice if there was Array.last()
22:34 <@Nexxy> _numbers, you mean like array[array.length-1] ?
22:35 < _numbers> ya--wait that works? :o
22:35 <@Nexxy> lol
22:35 < jrajav> Why wouldn't it?
22:35 < _numbers> i was goign to try Array.prototype.last = function (){ return this.slice(-1)[0]; } 
22:35 < jrajav> That's actually better than .slice(-1)[0]
22:35 < _numbers> ya
22:35 < _numbers> parallel[parallel.length-1]
22:36 < _numbers> its less cpu cycles but more to type in this example
22:36 < jrajav> Is there really any reason for this next function to be inside the array at all?
22:36 < jrajav> Check for length === 0 instead of 1
22:36 <@isaacs> niggler: what does .load do?
22:37 < jrajav> _numbers: It's not just less cycles, it also avoids creating a new array
22:37 < jrajav> _numbers: Worlds better performance-wise
22:37 < _numbers> Array.prototype.last = function (){ return this[this.length-1]; } 
22:37 <@isaacs> niggler: oh, hey, i always just use require()
22:38 < _numbers> http://codepen.io/mikesmullin/pen/efAyC
22:39 < jrajav> _numbers: As Nexxy and I already mentioned, defining methods on the array prototype is undesirable. You can do what you want just as easily by defining the method on that array, alone
22:39 < _numbers> no i agree. 
22:41 < garthk> isaacs, I'm about to try installing my own NPM. Your README makes it look easy. That true? :) https://github.com/isaacs/npmjs.org
22:41 <@isaacs> garthk: it's pretty easy for me :)
22:41 <@isaacs> garthk: getting the replication to work properly is a bit wonky
22:42 <@isaacs> garthk: i usually write a littel script that uses mikeal's "replicate" module rather than use the builtin continuous replication
22:42 < garthk> isaacs: call me a nutter, but wouldn't it be easier to have private NPMs *proxy* to the public one? 
22:42 <@isaacs> garthk: sure, you could do that
22:42 < _numbers> so parallel[parallel.length-1]();  is probably best
22:43 <@isaacs> garthk: but then it's not so trivial
22:43 <@isaacs> garthk: you could also have the private one replicate down only the packages you use.
22:43 < jrajav> _numbers: I still don't understand why that special function needs to be in the array
22:43 < garthk> isaacs: oh, the sync is dragging down module code as well as the metadata?
22:43 <@isaacs> garthk: yes
22:43 <@isaacs> garthk: the tarballs and everything are all inline in the db
22:44 < _numbers> jrajav: its natural to me. fork and share if you can think of a better way
22:45 < jrajav> Well, like I said, I'm probably gonna run with this. :)
22:45 < jrajav> Probably wouldn't finish anything today though
22:45 < niggler> isaacs what happens if you change a file and then call require?  will it give you the old instance or will it reload the file?
22:46 < _numbers> cool i'm interested when you do. 
22:47 < _numbers> regarding callback hell, i feel like modularizing is not solving the problem but obscuring it. if the entire src were viewed as a single file, it would be one giant boomerang. it seems like taking this pure-js array approach would help keep that final file more shallow
22:47 < jrajav> You said fork, do you have this up as a gist or something?
22:47 < jrajav> Or just codepen?
22:47 < _numbers> just codepen. same thing
22:48 < jrajav> I never learned a lot about codepen
22:48 < jrajav> I thought it was a lot like jsbin but geared more towards CSS
22:48 < _numbers> jrajav: its the best bin. does coffee, js, sass, scss, css, html, haml, slim, etc. all forkable 
22:48 < _numbers> jrajav: you can fork off of this and i will be able to see later http://codepen.io/mikesmullin/pen/olhbv
22:48 <@mbalho> _numbers: the process of modularization creates better (more understandable) APIs
22:49 <@Nexxy> _numbers, when you get down to it, it's still just registers full of numbers
22:49 < AviMarcus> jrajav, where will you be publishing this? I'm interested
22:49 < garbagecollectio> does mysql lock on reads or just writes
22:49 < garbagecollectio> or both
22:49 < jrajav> AviMarcus: I may take this opportunity to *finally* start publishing a blog.
22:50 < jrajav> AviMarcus: If not it will be a git repo or a gist
22:50 <@Nexxy> as mbalho mentions, the whole point of modularization is maintainability and ease of use
22:50 < AviMarcus> _numbers, but even when you do this, what happens when the parallel goes into another function, which goes into.. etc.
22:51 <@Nexxy> mbalho, I ordered moar lasers and some relays
22:51 < AviMarcus> _numbers,  How does the arrays help in sum, to make it more readable? I thought you just wanted cleaner async strategies
22:51 <@Nexxy> oh and servos
22:51 <@mbalho> Nexxy: i got a servo this week but am having issues programming it reliably
22:51 < _numbers> Nexxy: ya but modularization makes it so you have to have several files up at once to get the big picture. and its not more maintainable when you need to ask ^n maintainers to approve and coordinate pull requests
22:51 <@mbalho> Nexxy: it sucks so bad that firmata doesnt support serial
22:52 < jrajav> AviMarcus: For series, it lines the functions up in the order they will actually be called. For parallel, it groups the functions that will be called together into one discrete collection, visually and in actuality
22:52 <@Nexxy> mbalho, do they use a controller or something?
22:52 < _numbers> AviMarcus: to me its like building the register in advance
22:52 <@Nexxy> _numbers, if the modules are engineered properly, the scope of their functionality should be narrow enough to keep a mental image of
22:52 < DTrejo>  what happened to TJ's redis powered `npm-search`
22:53 < AviMarcus> so _numbers you'll have a huge list of arrays, then at the end, like 4 lines that run it all?
22:53 < DTrejo> npmbro info npm-search
22:53 < npmbro> DTrejo: Please see npm's documentation at https://duckduckgo.com/?q=site%3Ahttp%3A%2F%2Fnpmjs.org%2Fdoc%2F%20info%20npm-search
22:53 <@mbalho> Nexxy: no sorry the serial thing is unrelated to the servo other than i need to have 1 arduino control a servo and communicate with serial 
22:53 <@mbalho> Nexxy: but it is https://www.sparkfun.com/products/10333
22:53 < TehShrike> DTrejo: check out nodezoo
22:53 < DTrejo> (i was looking for a CLI thing)
22:53 < DTrejo> but thank you
22:53 < DTrejo> i like nipster the best
22:53 <@mbalho> Nexxy: im just getting weird, unpredictable behavior from basic sketches using the arduino Serial abstraction
22:53 < _numbers> AviMarcus: no not quite one gigantic linear array. but just falling back to the normal control structures of most languages like: for, if, and else
22:54 < _numbers> not adding new exponential levels of hierarchy just for flow control
22:54 <@Nexxy> mbalho, hmm
22:54 <@Nexxy> mbalho, you don't have the servo on pins 0 or 1, ya?
22:55 <@mbalho> Nexxy: im pretty sure i'm not doing anything incorrectly, its probably either a buggy arduino or a buggy servo (or buggy arduino libs)
22:55 <@mbalho> Nexxy: i was gonna ask if you knew a tutorial on PWM with only node-serialport
22:56 < _numbers> ah just found noduino. pretty bad ass
22:56 <@Nexxy> omg, *the* mikeal ?!
22:56  * Youdaman hugs mikeal
22:56 < jrajav> AviMarcus: _numbers: You guys want to give me email addresses, or just try to catch you in channel sometime? I don't know exactly how I'll publish this, but I like the idea of finally starting a blog. I want to think about it later in any case
22:56 <@Nexxy> mbalho, not that I'm aware of
22:57 <@Nexxy> mbalho, good question though
22:57 < garbagecollectio> how much do u all make
22:57 <@mbalho> Nexxy: johnny-five doesnt fit on a drone either
22:57 <@Nexxy> garbagecollectio, a million little â™¥ thingies per week
22:57 < DTrejo> does ROS fit on a drone?
22:58 <@mbalho> wat is ros
22:58 < DTrejo> I've seen drones running on ros
22:58 < DTrejo> robot operating systestem
22:58 <@Nexxy> mbalho, pretty sure there is an answer
22:58 <@mbalho> DTrejo: is that a specific thing or a category of things
22:58 < DTrejo> http://www.ros.org/news/2010/10/ros-interface-for-the-parrot-ardrone.html
22:58 < DTrejo> a category of things
22:58 < DTrejo> lets you teleoperate it
22:58 < DTrejo> and other random things depending on what library you add to it
22:59 <@mbalho> is it better than the linux that is already running on the drone?
22:59 < DTrejo> or ike my friend did this: http://www.ros.org/news/2010/11/ardrone-and-front-video.html
22:59 < DTrejo> apparently in 2010
22:59 < DTrejo> didnt realize it was that long ago
23:00 < ffog> join #haskell
23:00 -!- mode/#node.js [+o piscisaureus_] by ChanServ
23:00 < ffog> oops ;)
23:00 < mikeal> someone wants to get academic :)
23:00 <@Nexxy> lol
23:01 <@Nexxy> 2010 was just last thursday
23:01 < AviMarcus> jrajav, PM
23:01 < jrajav> I saw
23:01 < AviMarcus> 'night folks
23:01 < garbagecollectio> how much money do u make
23:01 < DTrejo> 0/year
23:01 < garbagecollectio> college?
23:01 < DTrejo> as a student
23:01 < DTrejo> :)
23:01 < garbagecollectio> i understand
23:02 < DTrejo> soon to change
23:02 < garbagecollectio> sucks
23:02 < DTrejo> not really
23:02 < DTrejo> i worked last year during school and made decent money for a programmer
23:02 <@Nexxy> wait, people make money from this programming stuff?
23:02 < garbagecollectio> some ppl do
23:02 < garbagecollectio> the "dev community"
23:02 <@Nexxy> get. out.
23:03 <@mbalho> programmers get crap salaries, you definitely want business school instead 
23:03 < garbagecollectio> no they dont
23:03 < garbagecollectio> 80-120k?
23:03 <@Nexxy> astronaut school
23:03 < garbagecollectio> 80k out of school?
23:03 <@Nexxy> or clown school
23:03 <@mbalho> oh yea space is coming back
23:03 <@mbalho> big time
23:04 < AvianFlu> hot dog making school
23:04 <@mbalho> space is the new big data
23:04 < garbagecollectio> yeah space is in
23:04 < AvianFlu> HOT DOGS NEVER GO OUT OF STYLE
23:04 <@Nexxy> AvianFlu, that's just ridiculous
23:04 < mikeal> bartenders make good money, and drink for free!
23:04 <@Nexxy> omg lol
23:04 < jrajav> hot dog making school? Just as ridiculous as business school, one could argue :P
23:04 < garbagecollectio> its hard to make money in business though
23:04 < garbagecollectio> really doctor profession is the best
23:04 <@Nexxy> pretty sure a fulltime bartender can out-earn just about anyone 
23:04 <@Nexxy> at a good bar
23:04 < garbagecollectio> no way
23:04 < mmalecki> tips.
23:04 < garbagecollectio> yeah but hes a bartender
23:04 <@mbalho> doctors have to look at naked people, business people dont
23:04 <@Nexxy> dude.
23:05 <@mbalho> so obviously business > doctor
23:05 < garbagecollectio> a garbage man in NYC makes 90k hes still a garbage man
23:05 <@Nexxy> what's wrong with that?
23:05 <@Nexxy> sanitation is important
23:05 < garbagecollectio> hes a garbage man
23:05 < garbagecollectio> yeah its not respected
23:05 <@Nexxy> you're being judgmental
23:05 < garbagecollectio> we all are
23:05 < jrajav> This whole thing is assuming salary == what makes a profession good
23:05 <@mbalho> maybe if you call them sanitation specialists like they're supposed to be called
23:05 <@Nexxy> what mbalho said
23:05 <@Nexxy> or alternatively, sanitation technician
23:07 < jrajav> "sanitation guru" or "sanitation ninja"
23:07 < jrajav> More marketable imo
23:07 < jrajav> :D
23:08 <@Nexxy> only within a certain demographic
23:08 <@Nexxy> which will remain nameless
23:14 < substack> garthk: iriscouch has a private npm as a service offering now
23:15 < garthk> substack: handy. Thanks. I'll run it past the corp paranoia team.
23:15 < garthk> (Not downplaying it: I'd love to use it.)
23:15 < substack> garthk: and JasonSmith runs it, so you can ask him if you have questions
23:17 < garthk> substack: copy that. While you're around, but: is converting streaming XML parser output into an event stream insane? I like that back-pressure works when I use es.pipeline()â€¦
23:17 < garthk> module = https://github.com/garthk/tagstream ; 40 lines of library code = https://github.com/garthk/tagstream/blob/master/lib/tagstream.js
23:17 < substack> garthk: there are already libs to do that!
23:18 < substack> sax, cheerio
23:18 < rklancer> Yo substack, I see you cross compiled node for ardrones
23:18 < substack> rklancer: I didn't, I just copied what maxogden already did
23:18 < rklancer> ahas
23:18 < garthk> substack: sax still seemed to push out events; perhaps I need to look harder. Will check cheerio.
23:19 < substack> garthk: I wrote http://npm.im/trumpet too
23:19 < substack> it's more just for html but xml should work
23:19 < niggler> there used to be something which showed how many times a module was downloaded in the past week/month
23:19 <@mbalho> npmjs.org
23:19 < niggler> but i dont see that on the package page anymore
23:19 < niggler> mbalho its not there
23:19 <@mbalho> niggler: oh crazy haha
23:20 < niggler> last time i looked at the site i swore it had those fields
23:20 < niggler> but now its gone!
23:20 < arpecop> aaaaand its gone
23:20 < arpecop> :)
23:21 < niggler> arpecop lol have you seen the remix?
23:21 < niggler> arpecop: http://www.youtube.com/watch?v=4TlPo0yCSa4 there we go :)
23:22 < garthk> substack: which of these would cope best with having 1.5TB of XML shoved through them at 120MB/s? 
23:23 < arpecop> niggler: ahahaha
23:23 < substack> garthk: well cheerio requires you to have the whole buffer in memory ahead of time
23:23 < substack> sax doesn't
23:23 < substack> I would just write a wrapper on top of sax probably
23:24 < jrajav> 1.5TB of XML holy hell
23:25 < garthk> I'm not sure sax will handle the speed requirement, but I'll check it if node-expat's deployment problems on Windows shits me too much. The streaming API also isn't quite what I need: I definitely want a stream-of-parsed-XML-bits, not a stream-of-XML-text. 
23:25 < jrajav> That would be a good case for using a more compact transport protocol
23:25 < jrajav> It could be 1TB of JSON/YAML or maybe 7-800MB of a custom serialization format
23:26 < garthk> Oh, it gets worse, jrajav. The Perl I'm replacing is scanning the 1.5TB seven times, and really needs to scan through it more because it's still trying to load too much data into RAM on each pass and OOMs even on a 96GB machine. :)
23:26 < jrajav> *GB
23:26 < jrajav> (Correcting mine)
23:26 < jrajav> That is pretty insane
23:27 < garthk> Yeah, one of my tactics is to pre-filter it as it's downloaded, perhaps by parodying the machine from which it's pulled. That way I can throw out around 85% of it. That said, the final engine is still going to OOM or have to scan through it a lot more than seven times. My eventual goal is to replace it and generate the graphs in a smarter fashion. 
23:27 < TehShrike> garthk: definitely write something using sax
23:28 < TehShrike> sax is made for your case perfectly
23:28 < TehShrike> Stream XML at it
23:28 < bsnote> Still not able to cross-compile node.js for MIPS platform (mips-linux-4.4-codesourcery toolchain):
23:28 < bsnote> $ export AR=mips-linux-gnu-ar
23:28 < bsnote> $ export CC=mips-linux-gnu-gcc
23:28 < bsnote> $ export CXX=mips-linux-gnu-g++
23:28 < bsnote> $ export LINK=mips-linux-gnu-g++
23:28 < bsnote> $ export RANLIB=mips-linux-gnu-ranlib
23:28 < bsnote> $ export CFLAGS='-march=mips32'
23:28 < bsnote> $ export CCFLAGS='-march=mips32'
23:28 < bsnote> $ export CXXFLAGS='-march=mips32'
23:28 < bsnote> ./configure --without-snapshot --dest-cpu=mips --dest-os=linux --without-ssl
23:28 < bsnote> make
23:28 < bsnote> getting a bunch of errors like:
23:28 < bsnote> mips-linux-gnu/bin/ld: /home/simpletv/git/node/out/Release/obj.target/v8_base/deps/v8/src/bootstrapper.o: compiled for a little endian system and target is big endian
23:28 < bsnote> mips-linux-gnu/bin/ld: /home/simpletv/git/node/out/Release/obj.target/v8_base/deps/v8/src/bootstrapper.o: endianness incompatible with that of the selected emulation
23:28 < TehShrike> bsnote: use a pastebin!  Don't paste code in chat
23:31 < garthk> TehShrike: substack said that, too, but I really want to pipe XML text in and get a stream of objects like { what: "start", tag: "X" } fragments out. Then I can hook up a nice long pipeline through filters and processors which operate on objects, and eventually have one spit buffers or strings out, and pipe it into a file, and have back-pressure work properly through the whole thing.
23:31 < garthk> Despite the origin servers delivering at 120MB/s, some of the clients will be downloading at a MUCH slower speed than that. Node will, as I understand it, have a bad time with memory if I don't apply back-pressure properly.
23:32 < TehShrike> garthk: I imagine sax and streams would be perfect for that
23:32 < substack> seems so yes
23:32 < niggler> how does licensing work for a module that includes another module?
23:32 < garthk> So, I'm rolling with what I through was substack's "stream all the things" philosophy, but which might actually come from dominictarr now that I think of it. :)
23:32 < substack> dominictarr was into streams years ago before they were cool
23:33 < niggler> https://github.com/dominiklessel/xlsx uses https://github.com/stephen-hardy/xlsx.js and the former claims to be MIT whereas it has, in verbatim, code under a different license
23:33 < DTrejo> garthk: sounds like a fun project, as horrible as it is
23:33 < substack> garthk: https://github.com/substack/stream-handbook#backpressure
23:33 < TehShrike> It sounds fun because it sounds like the situation streams were made for :-P
23:33 < substack> implement pause() and resume() and return false in write() when you want the source to slow down
23:34 < substack> or you could use streams2 https://github.com/isaacs/readable-stream
23:34 < garthk> TehShrike substackâ€¦ except SAXStream doesn't actually output a stream of objects. It outputs the original XML text again. I could hook up the tag and text events to another stream and write code to handle the back-pressure, but then I end up back with the tag stream library I just wrote. :)
23:34 < substack> garthk: check out JSONStream for api inspiration
23:34 < garthk> That's why it's only 40 lines. (Outnumbered 2:1 by tests FTW!) 
23:34 < substack> it's a stream that outputs nested object data
23:35 < niggler> substack in your missive " the API for handling backpressure is changing substantially in future versions of node" -- what is the planned API
23:35 < TehShrike> garthk: what? It doesn't output XML
23:35 < TehShrike> garthk: it emits on open tag, close tag, text, etc
23:36 < TehShrike> garthk: you set your handlers on all of those and then built your objects however is appropriate based on what your tags and their contents mean
23:36 < garthk> substack: JSONstream is exactly what I had in mind when I implemented tagstream, yes. (And, I'll ditch node-expat as a dependency and replace it with sax if it can keep up.)
23:36 < TehShrike> garthk: if you want to see sax used to turn XML into objects, check out my module sax-bastard on npm
23:37 < TehShrike> There, I just do it all in memory, no streams or anything - obviously your method would need to be a bit more intelligent there
23:37 < garthk> TehShrike: that's exactly my point. Sax emits open, close, and text. It doesn't emit 'data' the way I want, though. When it emits 'data', the argument is the XML text. What I want is for it to emit { what: "open", tag: "X" } etc.
23:37 < TehShrike> uh... well, that's not that hard to add
23:37 < niggler> there's no git link?
23:38 < TehShrike> niggler: no, it's in the company repository at the moment, which isn't github :-(
23:38 < garthk> So, I've got to adapt it to behave the way I want, which is perfectly possible, and indeed is exactly what I did. And I published it as a 40-line library because I want to break out the responsibility of that adaptation.
23:38 < niggler> if its git
23:38 < TehShrike> It's SVN.
23:38 < niggler> ooh ok
23:38 < niggler> ( TehShrike  there exists a massive git universe outside of github)
23:39 < TehShrike> niggler: sure, but even if my company was using git, it wouldn't be publicly accessible
23:39 < TehShrike> garthk: what does your library do, emit objects?
23:40 < garthk> TehShrike: this.emit('data', xmlParserEventInformationAsAnObject); // yes
23:40 < TehShrike> garthk: how would your object be built from XML - is your data ever only one element deep?
23:41 < garthk> TehShrike: oh, you should see the XML. It's horrible. :) Imagine XML as written by a database guy who's really bloody good at third normal form but doesn't understand or care about why we call XML data "documents".
23:41 < garthk> <rows><row>â€¦</row>â€¦</rows><!-- I shit you not â†’
23:41 < TehShrike> Maybe you want what sax-bastard does, but emitting the current object and starting another one whenever current_object === root_object
23:41 < TehShrike> garthk: aahk >_<
23:43 < garthk> Well, I've got two formats. The horrid one is usually nice and small. Sometimes, though, it's a few hundred KB, and â€” worse â€” when it's that long it contains hundreds of details for which in turn I need to generate a few dozen more requests each, and that ends up in yet another backpressure-rich situation. 
23:43 < TehShrike> And that's why we have streams! :-)
23:43 < garthk> And, the other one is the one where I end up with 1.5TB of data. It's a simpler, more sensible format; there's just a bloody awful lot of it.
23:44 < garthk> TehShrike: right! So, I'm taking XML parsing and making it just slightly more streamified because that makes the rest of my life slightly less miserable. :)
23:45 < garthk> Anyhoo, that's enough talking for now. I still think I'm on the right track. That tiny module has just the right combination of "I don't get why you would ever need to do that" and "it's not necessary", sometimes both from the same people. :)
23:45 < TehShrike> Hah :-P
23:45 < TehShrike> Where is it?
23:45 <@Nexxy> mbalho, I want your warehouse.
23:46 < garthk> https://npmjs.org/package/tagstream but I'm going to edit the README to steal the first line of the JSONstream README because it explains WTF I'm doing a lot better. 
23:48 < garthk> Oh, it's the description in package.json. Heh.
23:53 <@mbalho> Nexxy: haha yea it is fun
23:56 < _numbers> has anyone else had the experience of inheriting a dependency that was compiled by iced coffeescript, and found it was generally unreadable? https://github.com/maxtaco/coffee-script/issues/47
23:57 <@mbalho> _numbers: thats why i dont tolerate compile-to languages :D
--- Log closed Mon Dec 03 00:00:21 2012
